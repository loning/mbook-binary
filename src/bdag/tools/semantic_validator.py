#!/usr/bin/env python3
"""
BDAG Semantic Validator
Deep validation of theoretical consistency and mathematical correctness
"""

import re
from typing import List, Dict, Set, Tuple
from pathlib import Path
from bdag_core import TensorNode

class SemanticValidator:
    """BDAGè¯­ä¹‰éªŒè¯å™¨"""
    
    def __init__(self, nodes: Dict[str, TensorNode]):
        self.nodes = nodes
        self.errors: List[str] = []
        self.warnings: List[str] = []
        
        # å®šä¹‰å·²çŸ¥çš„æ•°å­¦å…³ç³»
        self.math_relations = {
            'phi_fibonacci': r'F_n.*Ï†.*golden.*ratio',
            'entropy_increase': r'H\(.*\).*>.*H\(',
            'zeckendorf_unique': r'unique.*representation.*Fibonacci',
            'self_reference': r'S\(S\)|S.*=.*S\(S\)'
        }
        
        # ç‰©ç†ç»´åº¦å®šä¹‰
        self.dimensions = {
            'SelfRefTensor': {'information': 1, 'time': 0},
            'EntropyTensor': {'information': 1, 'time': -1},
            'GoldenRatio': {'dimensionless': 1},
            'ZeckendorfSystem': {'information': 1},
            'InfoTensor': {'information': 1, 'time': -1}
        }
    
    def validate_semantic_consistency(self) -> Tuple[List[str], List[str]]:
        """æ‰§è¡Œè¯­ä¹‰ä¸€è‡´æ€§éªŒè¯"""
        self.errors.clear()
        self.warnings.clear()
        
        self._validate_mathematical_consistency()
        self._validate_dimensional_analysis()
        self._validate_phi_encoding_rules()
        self._validate_entropy_monotonicity()
        self._validate_content_filename_match()
        
        return self.errors.copy(), self.warnings.copy()
    
    def _validate_mathematical_consistency(self):
        """éªŒè¯æ•°å­¦ä¸€è‡´æ€§"""
        for node in self.nodes.values():
            if node.operation.value == 'DEFINE':
                self._check_definition_completeness(node)
            elif node.operation.value == 'APPLY':
                self._check_application_validity(node)
            elif node.operation.value == 'COMBINE':
                self._check_combination_rules(node)
    
    def _check_definition_completeness(self, node: TensorNode):
        """æ£€æŸ¥å®šä¹‰çš„å®Œæ•´æ€§"""
        # è¯»å–å¯¹åº”çš„æ–‡ä»¶å†…å®¹
        content = self._read_node_content(node)
        if not content:
            self.errors.append(f"æ— æ³•è¯»å– {node.full_id} çš„æ–‡ä»¶å†…å®¹")
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­¦è¡¨ç¤º
        if '$$' not in content and '$' not in content:
            self.warnings.append(f"{node.full_id}: ç¼ºå°‘æ•°å­¦è¡¨ç¤º")
        
        # æ£€æŸ¥ç‰¹å®šçš„æ•°å­¦å…³ç³»
        if node.name == 'Phi' and 'varphi' not in content:
            self.errors.append(f"{node.full_id}: Ï†å®šä¹‰ä¸­ç¼ºå°‘æ•°å­¦ç¬¦å·")
        
        if node.name == 'SelfReference' and not re.search(self.math_relations['self_reference'], content):
            self.warnings.append(f"{node.full_id}: è‡ªæŒ‡å…³ç³»è¡¨è¾¾ä¸æ¸…æ™°")
    
    def _check_application_validity(self, node: TensorNode):
        """æ£€æŸ¥åº”ç”¨æ“ä½œçš„æœ‰æ•ˆæ€§"""
        content = self._read_node_content(node)
        if not content:
            return
        
        # æ£€æŸ¥ç†µå¢æ“ä½œ
        if 'Entropy' in node.name and not re.search(self.math_relations['entropy_increase'], content):
            self.warnings.append(f"{node.full_id}: ç†µå¢æ€§è´¨æœªæ˜ç¡®è¡¨è¾¾")
        
        # æ£€æŸ¥Ï†ç¼–ç æ“ä½œ
        if 'Phi' in node.name and not re.search(self.math_relations['zeckendorf_unique'], content):
            self.warnings.append(f"{node.full_id}: Zeckendorfå”¯ä¸€æ€§æœªè¯´æ˜")
    
    def _check_combination_rules(self, node: TensorNode):
        """æ£€æŸ¥ç»„åˆæ“ä½œçš„è§„åˆ™"""
        if len(node.inputs) < 2:
            self.errors.append(f"{node.full_id}: COMBINEæ“ä½œéœ€è¦è‡³å°‘2ä¸ªè¾“å…¥")
        
        # æ£€æŸ¥è¾“å…¥ä¹‹é—´çš„å…¼å®¹æ€§
        input_types = []
        for inp in node.inputs:
            if inp.id in self.nodes:
                input_node = self.nodes[inp.id]
                input_types.append(input_node.output_type)
        
        # éªŒè¯ç»„åˆçš„æ•°å­¦æ„ä¹‰
        content = self._read_node_content(node)
        if content and 'otimes' not in content and 'tensor' not in content.lower():
            self.warnings.append(f"{node.full_id}: ç»„åˆæ“ä½œçš„æ•°å­¦å½¢å¼ä¸æ¸…æ™°")
    
    def _validate_dimensional_analysis(self):
        """éªŒè¯ç‰©ç†ç»´åº¦åˆ†æ"""
        for node in self.nodes.values():
            if node.output_type in self.dimensions:
                expected_dims = self.dimensions[node.output_type]
                
                # æ£€æŸ¥è¾“å…¥ç»´åº¦çš„ä¸€è‡´æ€§
                for inp in node.inputs:
                    if inp.id in self.nodes:
                        input_node = self.nodes[inp.id]
                        if input_node.output_type in self.dimensions:
                            self._check_dimensional_compatibility(node, input_node)
    
    def _check_dimensional_compatibility(self, node: TensorNode, input_node: TensorNode):
        """æ£€æŸ¥ç»´åº¦å…¼å®¹æ€§"""
        output_dims = self.dimensions.get(node.output_type, {})
        input_dims = self.dimensions.get(input_node.output_type, {})
        
        # å¯¹äºAPPLYæ“ä½œï¼Œè¾“å…¥è¾“å‡ºç»´åº¦åº”è¯¥æœ‰æ˜ç¡®å…³ç³»
        if node.operation.value == 'APPLY':
            if 'Entropy' in node.name and 'information' not in output_dims:
                self.errors.append(f"{node.full_id}: ç†µæ“ä½œåº”è¯¥è¾“å‡ºä¿¡æ¯ç»´åº¦")
    
    def _validate_phi_encoding_rules(self):
        """éªŒè¯Ï†ç¼–ç è§„åˆ™"""
        phi_nodes = [n for n in self.nodes.values() if 'Phi' in n.name or 'phi' in n.name.lower()]
        
        for node in phi_nodes:
            content = self._read_node_content(node)
            if content:
                # æ£€æŸ¥No-11çº¦æŸ
                if 'No-11' not in content and '11' in content:
                    self.warnings.append(f"{node.full_id}: åº”è¯¥æ˜ç¡®No-11çº¦æŸ")
                
                # æ£€æŸ¥Fibonacciå…³ç³»
                if 'Fibonacci' not in content and 'F_n' not in content:
                    self.warnings.append(f"{node.full_id}: ç¼ºå°‘Fibonacciå…³ç³»è¯´æ˜")
    
    def _validate_entropy_monotonicity(self):
        """éªŒè¯ç†µçš„å•è°ƒæ€§"""
        entropy_nodes = [n for n in self.nodes.values() if 'Entropy' in n.name]
        
        for node in entropy_nodes:
            if 'Monotonic' not in node.attributes:
                self.warnings.append(f"{node.full_id}: ç†µæ“ä½œåº”è¯¥æ ‡è®°ä¸ºMonotonic")
            
            if 'Irreversible' not in node.attributes:
                self.warnings.append(f"{node.full_id}: ç†µæ“ä½œåº”è¯¥æ ‡è®°ä¸ºIrreversible")
    
    def _validate_content_filename_match(self):
        """éªŒè¯æ–‡ä»¶å†…å®¹ä¸æ–‡ä»¶åçš„åŒ¹é…"""
        for node in self.nodes.values():
            content = self._read_node_content(node)
            if not content:
                continue
            
            # æ£€æŸ¥æ“ä½œç±»å‹æ˜¯å¦åœ¨å†…å®¹ä¸­ä½“ç°
            op_keywords = {
                'DEFINE': ['å®šä¹‰', 'define', 'å¼ é‡å®šä¹‰'],
                'APPLY': ['åº”ç”¨', 'apply', 'ç®—å­'],
                'COMBINE': ['ç»„åˆ', 'combine', 'å¼ é‡ç§¯', 'otimes'],
                'EMERGE': ['æ¶Œç°', 'emerge', 'æ–°æ€§è´¨'],
                'DERIVE': ['æ¨å¯¼', 'derive', 'æ¨å¯¼å‡º']
            }
            
            expected_keywords = op_keywords.get(node.operation.value, [])
            if not any(keyword in content.lower() for keyword in expected_keywords):
                self.warnings.append(f"{node.full_id}: å†…å®¹ä¸æ“ä½œç±»å‹ {node.operation.value} ä¸åŒ¹é…")
    
    def _read_node_content(self, node: TensorNode) -> str:
        """è¯»å–èŠ‚ç‚¹å¯¹åº”çš„æ–‡ä»¶å†…å®¹"""
        try:
            # å‡è®¾æ–‡ä»¶åœ¨examplesç›®å½•ä¸­
            file_path = Path(__file__).parent.parent / "examples" / node.filename
            if file_path.exists():
                return file_path.read_text(encoding='utf-8')
        except Exception as e:
            pass
        return ""
    
    def generate_report(self) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = ["BDAGè¯­ä¹‰éªŒè¯æŠ¥å‘Š", "=" * 40]
        
        if self.errors:
            report.append(f"\nğŸš¨ é”™è¯¯ ({len(self.errors)} ä¸ª):")
            for i, error in enumerate(self.errors, 1):
                report.append(f"  {i}. {error}")
        
        if self.warnings:
            report.append(f"\nâš ï¸  è­¦å‘Š ({len(self.warnings)} ä¸ª):")
            for i, warning in enumerate(self.warnings, 1):
                report.append(f"  {i}. {warning}")
        
        if not self.errors and not self.warnings:
            report.append("\nâœ… æ‰€æœ‰è¯­ä¹‰æ£€æŸ¥é€šè¿‡!")
        
        return "\n".join(report)

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # è¿™é‡Œéœ€è¦åŠ è½½å®é™…çš„èŠ‚ç‚¹æ•°æ®
    print("è¯­ä¹‰éªŒè¯å™¨å·²å‡†å¤‡å°±ç»ª")