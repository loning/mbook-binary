#!/usr/bin/env python3
"""
Classification Statistics Generator v3.0
ç”ŸæˆT{n}ç†è®ºäº”ç±»åˆ†ç±»ç³»ç»Ÿçš„è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
"""

import math
from typing import Dict, List, Tuple
from collections import defaultdict
from pathlib import Path

try:
    from .theory_parser import TheoryParser, FibonacciOperationType
    from .theory_validator import PrimeChecker
except ImportError:
    from theory_parser import TheoryParser, FibonacciOperationType
    from theory_validator import PrimeChecker

class ClassificationStatistics:
    """äº”ç±»ç†è®ºåˆ†ç±»ç»Ÿè®¡åˆ†æå™¨"""
    
    def __init__(self, max_theory: int = 997):
        self.max_theory = max_theory
        self.parser = TheoryParser(max_theory)
        self.prime_checker = PrimeChecker()
        self.phi = (1 + math.sqrt(5)) / 2  # é»„é‡‘æ¯”ä¾‹
        
        # ç”ŸæˆåŸºç¡€æ•°æ®
        self.fibonacci_set = set(self.parser.fibonacci_sequence)
        self.primes = self.prime_checker.get_primes_up_to(max_theory)
        self.prime_set = set(self.primes)
        
    def classify_theory(self, n: int) -> str:
        """å¯¹ç†è®ºè¿›è¡Œäº”ç±»åˆ†ç±»"""
        if n == 1:
            return "AXIOM"
        elif n in self.fibonacci_set and n in self.prime_set:
            return "PRIME-FIB"
        elif n in self.fibonacci_set:
            return "FIBONACCI"
        elif n in self.prime_set:
            return "PRIME"
        else:
            return "COMPOSITE"
    
    def generate_complete_statistics(self) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ç±»ç»Ÿè®¡"""
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        classification_counts = defaultdict(int)
        classification_examples = defaultdict(list)
        classification_ranges = defaultdict(list)
        
        for n in range(1, self.max_theory + 1):
            cls = self.classify_theory(n)
            classification_counts[cls] += 1
            
            # æ”¶é›†å‰10ä¸ªç¤ºä¾‹
            if len(classification_examples[cls]) < 10:
                classification_examples[cls].append(n)
        
        total = self.max_theory
        
        # è®¡ç®—ç†è®ºå¯†åº¦
        densities = self._calculate_densities()
        
        # åˆ†æç‰¹æ®Šå­ç±»
        special_analysis = self._analyze_special_subcategories()
        
        # åˆ†å¸ƒåˆ†æ
        distribution_analysis = self._analyze_distribution_patterns()
        
        return {
            'meta': {
                'total_theories': total,
                'max_theory': self.max_theory,
                'analysis_date': 'v3.0'
            },
            'classification_counts': dict(classification_counts),
            'classification_percentages': {
                cls: (count / total) * 100 
                for cls, count in classification_counts.items()
            },
            'classification_examples': dict(classification_examples),
            'theoretical_densities': densities,
            'special_analysis': special_analysis,
            'distribution_patterns': distribution_analysis,
            'comparative_analysis': self._comparative_analysis(classification_counts, total)
        }
    
    def _calculate_densities(self) -> Dict:
        """è®¡ç®—ç†è®ºå¯†åº¦"""
        n = self.max_theory
        
        # ç´ æ•°å¯†åº¦ï¼ˆç´ æ•°å®šç†ï¼‰
        prime_density_theoretical = n / math.log(n) if n > 1 else 0
        prime_density_actual = len(self.primes)
        
        # Fibonacciå¯†åº¦
        fibonacci_density_actual = len([f for f in self.fibonacci_set if f <= n])
        fibonacci_density_theoretical = math.log(n) / math.log(self.phi) if n > 1 else 0
        
        # PRIME-FIBå¯†åº¦ï¼ˆäº¤é›†ï¼‰
        prime_fib_actual = len([x for x in range(1, n+1) 
                               if x in self.prime_set and x in self.fibonacci_set])
        
        return {
            'prime': {
                'theoretical': prime_density_theoretical,
                'actual': prime_density_actual,
                'accuracy': prime_density_actual / prime_density_theoretical if prime_density_theoretical > 0 else 0
            },
            'fibonacci': {
                'theoretical': fibonacci_density_theoretical,
                'actual': fibonacci_density_actual,
                'accuracy': fibonacci_density_actual / fibonacci_density_theoretical if fibonacci_density_theoretical > 0 else 0
            },
            'prime_fib_intersection': {
                'actual': prime_fib_actual,
                'rarity_factor': n / prime_fib_actual if prime_fib_actual > 0 else float('inf')
            }
        }
    
    def _analyze_special_subcategories(self) -> Dict:
        """åˆ†æç‰¹æ®Šå­ç±»åˆ«"""
        
        # ç‰¹æ®Šç´ æ•°ç±»å‹
        twin_primes = []
        mersenne_primes = []
        sophie_germain_primes = []
        
        for p in self.primes:
            if p <= self.max_theory:
                if self.prime_checker.is_twin_prime(p):
                    twin_primes.append(p)
                if self.prime_checker.is_mersenne_prime(p):
                    mersenne_primes.append(p)
                if self.prime_checker.is_sophie_germain_prime(p):
                    sophie_germain_primes.append(p)
        
        # åˆ†æFibonacciæ•°çš„ç´ å› å­ç»“æ„
        fibonacci_factorizations = {}
        for fib in self.fibonacci_set:
            if fib <= self.max_theory and fib > 1:
                factors = self.prime_checker.prime_factorize(fib)
                fibonacci_factorizations[fib] = factors
        
        # åˆ†æPRIME-FIBç†è®ºçš„ç¨€æœ‰æ€§
        prime_fib_theories = [n for n in range(1, self.max_theory + 1)
                             if n in self.prime_set and n in self.fibonacci_set]
        
        return {
            'special_prime_types': {
                'twin_primes': {
                    'count': len(twin_primes),
                    'examples': twin_primes[:10],
                    'percentage': len(twin_primes) / len(self.primes) * 100
                },
                'mersenne_primes': {
                    'count': len(mersenne_primes),
                    'examples': mersenne_primes,
                    'percentage': len(mersenne_primes) / len(self.primes) * 100
                },
                'sophie_germain_primes': {
                    'count': len(sophie_germain_primes),
                    'examples': sophie_germain_primes[:10],
                    'percentage': len(sophie_germain_primes) / len(self.primes) * 100
                }
            },
            'fibonacci_factorizations': fibonacci_factorizations,
            'prime_fib_rarity': {
                'total_count': len(prime_fib_theories),
                'theories': prime_fib_theories,
                'gaps_between': [prime_fib_theories[i+1] - prime_fib_theories[i] 
                               for i in range(len(prime_fib_theories)-1)] if len(prime_fib_theories) > 1 else [],
                'average_gap': sum([prime_fib_theories[i+1] - prime_fib_theories[i] 
                                  for i in range(len(prime_fib_theories)-1)]) / (len(prime_fib_theories)-1) if len(prime_fib_theories) > 1 else 0
            }
        }
    
    def _analyze_distribution_patterns(self) -> Dict:
        """åˆ†æåˆ†å¸ƒæ¨¡å¼"""
        
        # åˆ†æ®µåˆ†æ
        segments = [
            (1, 50, "Early Universe"),
            (51, 100, "Foundation"),
            (101, 200, "Expansion"),
            (201, 500, "Complexity"),
            (501, 997, "Advanced")
        ]
        
        segment_analysis = {}
        for start, end, name in segments:
            segment_stats = defaultdict(int)
            for n in range(start, min(end + 1, self.max_theory + 1)):
                cls = self.classify_theory(n)
                segment_stats[cls] += 1
            
            total_in_segment = sum(segment_stats.values())
            segment_analysis[name] = {
                'range': f"T{start}-T{end}",
                'counts': dict(segment_stats),
                'percentages': {cls: (count / total_in_segment) * 100 
                              for cls, count in segment_stats.items()} if total_in_segment > 0 else {},
                'dominant_type': max(segment_stats, key=segment_stats.get) if segment_stats else None
            }
        
        return {
            'segment_analysis': segment_analysis,
            'clustering_analysis': self._analyze_clustering()
        }
    
    def _analyze_clustering(self) -> Dict:
        """åˆ†æèšç±»æ¨¡å¼"""
        
        # åˆ†æè¿ç»­ç›¸åŒç±»å‹çš„ç†è®º
        clusters = defaultdict(list)
        current_cluster = []
        current_type = None
        
        for n in range(1, self.max_theory + 1):
            cls = self.classify_theory(n)
            
            if cls == current_type:
                current_cluster.append(n)
            else:
                if current_cluster and len(current_cluster) > 1:
                    clusters[current_type].append(current_cluster.copy())
                current_cluster = [n]
                current_type = cls
        
        # æ·»åŠ æœ€åä¸€ä¸ªèšç±»
        if current_cluster and len(current_cluster) > 1:
            clusters[current_type].append(current_cluster)
        
        # ç»Ÿè®¡èšç±»ä¿¡æ¯
        cluster_stats = {}
        for cls, cluster_list in clusters.items():
            if cluster_list:
                cluster_sizes = [len(cluster) for cluster in cluster_list]
                cluster_stats[cls] = {
                    'cluster_count': len(cluster_list),
                    'max_cluster_size': max(cluster_sizes),
                    'avg_cluster_size': sum(cluster_sizes) / len(cluster_sizes),
                    'total_clustered': sum(cluster_sizes),
                    'largest_clusters': sorted(cluster_list, key=len, reverse=True)[:3]
                }
        
        return cluster_stats
    
    def _comparative_analysis(self, counts: Dict, total: int) -> Dict:
        """æ¯”è¾ƒåˆ†æ"""
        
        # ä¸ç†è®ºé¢„æœŸçš„æ¯”è¾ƒ
        expected_ratios = {
            'AXIOM': 1 / total,  # åªæœ‰1ä¸ª
            'PRIME-FIB': 0.006,  # æç¨€æœ‰
            'FIBONACCI': 0.015,  # ç¨€æœ‰
            'PRIME': 0.15,       # æ ¹æ®ç´ æ•°å®šç†
            'COMPOSITE': 0.829   # å¤§éƒ¨åˆ†
        }
        
        actual_ratios = {cls: count / total for cls, count in counts.items()}
        
        ratio_comparison = {}
        for cls in expected_ratios:
            expected = expected_ratios[cls]
            actual = actual_ratios.get(cls, 0)
            ratio_comparison[cls] = {
                'expected': expected,
                'actual': actual,
                'deviation': abs(actual - expected) / expected if expected > 0 else 0,
                'ratio': actual / expected if expected > 0 else 0
            }
        
        return {
            'ratio_comparison': ratio_comparison,
            'diversity_index': self._calculate_diversity_index(counts, total),
            'mathematical_consistency': self._check_mathematical_consistency(counts)
        }
    
    def _calculate_diversity_index(self, counts: Dict, total: int) -> float:
        """è®¡ç®—å¤šæ ·æ€§æŒ‡æ•°ï¼ˆShannonç†µï¼‰"""
        entropy = 0
        for count in counts.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)
        return entropy
    
    def _check_mathematical_consistency(self, counts: Dict) -> Dict:
        """æ£€æŸ¥æ•°å­¦ä¸€è‡´æ€§"""
        
        # æ£€æŸ¥æ€»æ•°
        total_from_counts = sum(counts.values())
        expected_total = self.max_theory
        
        # æ£€æŸ¥AXIOMæ•°é‡
        axiom_correct = counts.get('AXIOM', 0) == 1
        
        # æ£€æŸ¥ç´ æ•°æ€»æ•°
        prime_total = counts.get('PRIME', 0) + counts.get('PRIME-FIB', 0)
        expected_primes = len(self.primes)
        
        # æ£€æŸ¥Fibonacciæ€»æ•°
        fib_total = counts.get('FIBONACCI', 0) + counts.get('PRIME-FIB', 0)
        expected_fibs = len([f for f in self.fibonacci_set if f <= self.max_theory])
        
        return {
            'total_consistency': total_from_counts == expected_total,
            'axiom_consistency': axiom_correct,
            'prime_consistency': prime_total == expected_primes,
            'fibonacci_consistency': fib_total == expected_fibs,
            'details': {
                'total': {'actual': total_from_counts, 'expected': expected_total},
                'primes': {'actual': prime_total, 'expected': expected_primes},
                'fibonacci': {'actual': fib_total, 'expected': expected_fibs}
            }
        }
    
    def generate_report(self, output_file: str = None) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        
        stats = self.generate_complete_statistics()
        
        report = []
        report.append("ğŸ”¬ T{n}ç†è®ºäº”ç±»åˆ†ç±»ç»Ÿè®¡æŠ¥å‘Š v3.0")
        report.append("=" * 60)
        
        # åŸºæœ¬ç»Ÿè®¡
        report.append(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡ (T1-T{self.max_theory})")
        report.append("-" * 40)
        report.append(f"æ€»ç†è®ºæ•°: {stats['meta']['total_theories']}")
        
        for cls, count in stats['classification_counts'].items():
            percentage = stats['classification_percentages'][cls]
            examples = ", ".join(f"T{x}" for x in stats['classification_examples'][cls][:5])
            report.append(f"{cls:12s}: {count:4d} ({percentage:5.2f}%) - ç¤ºä¾‹: {examples}")
        
        # å¯†åº¦åˆ†æ
        report.append(f"\nğŸ¯ ç†è®ºå¯†åº¦åˆ†æ")
        report.append("-" * 40)
        densities = stats['theoretical_densities']
        
        report.append(f"ç´ æ•°å¯†åº¦:")
        report.append(f"  ç†è®ºå€¼: {densities['prime']['theoretical']:.1f}")
        report.append(f"  å®é™…å€¼: {densities['prime']['actual']}")
        report.append(f"  å‡†ç¡®åº¦: {densities['prime']['accuracy']*100:.1f}%")
        
        report.append(f"Fibonacciå¯†åº¦:")
        report.append(f"  ç†è®ºå€¼: {densities['fibonacci']['theoretical']:.1f}")
        report.append(f"  å®é™…å€¼: {densities['fibonacci']['actual']}")
        
        report.append(f"PRIME-FIBç¨€æœ‰åº¦:")
        report.append(f"  æ€»æ•°: {densities['prime_fib_intersection']['actual']}")
        report.append(f"  ç¨€æœ‰å› å­: {densities['prime_fib_intersection']['rarity_factor']:.1f}")
        
        # ç‰¹æ®Šåˆ†æ
        report.append(f"\nâ­ ç‰¹æ®Šç†è®ºåˆ†æ")
        report.append("-" * 40)
        special = stats['special_analysis']
        
        # PRIME-FIBç†è®º
        prime_fib_info = special['prime_fib_rarity']
        report.append(f"PRIME-FIBåŒé‡ç†è®º: {prime_fib_info['theories']}")
        if prime_fib_info['gaps_between']:
            report.append(f"ç†è®ºé—´å¹³å‡é—´éš”: {prime_fib_info['average_gap']:.1f}")
        
        # ç‰¹æ®Šç´ æ•°ç±»å‹
        report.append(f"\nç‰¹æ®Šç´ æ•°ç±»å‹:")
        for prime_type, info in special['special_prime_types'].items():
            if info['count'] > 0:
                report.append(f"  {prime_type}: {info['count']}ä¸ª ({info['percentage']:.1f}%)")
                report.append(f"    ç¤ºä¾‹: {info['examples'][:5]}")
        
        # åˆ†æ®µåˆ†æ
        report.append(f"\nğŸ“ˆ åˆ†æ®µåˆ†å¸ƒåˆ†æ")
        report.append("-" * 40)
        for segment_name, segment_data in stats['distribution_patterns']['segment_analysis'].items():
            report.append(f"{segment_name} {segment_data['range']}:")
            report.append(f"  ä¸»å¯¼ç±»å‹: {segment_data['dominant_type']}")
            for cls, percentage in segment_data['percentages'].items():
                if percentage > 5:  # åªæ˜¾ç¤º>5%çš„ç±»å‹
                    report.append(f"  {cls}: {percentage:.1f}%")
        
        # æ•°å­¦ä¸€è‡´æ€§
        report.append(f"\nâœ… æ•°å­¦ä¸€è‡´æ€§éªŒè¯")
        report.append("-" * 40)
        consistency = stats['comparative_analysis']['mathematical_consistency']
        report.append(f"æ€»æ•°ä¸€è‡´æ€§: {'âœ…' if consistency['total_consistency'] else 'âŒ'}")
        report.append(f"å…¬ç†ä¸€è‡´æ€§: {'âœ…' if consistency['axiom_consistency'] else 'âŒ'}")
        report.append(f"ç´ æ•°ä¸€è‡´æ€§: {'âœ…' if consistency['prime_consistency'] else 'âŒ'}")
        report.append(f"Fibonacciä¸€è‡´æ€§: {'âœ…' if consistency['fibonacci_consistency'] else 'âŒ'}")
        
        # å¤šæ ·æ€§æŒ‡æ•°
        diversity = stats['comparative_analysis']['diversity_index']
        report.append(f"\nå¤šæ ·æ€§æŒ‡æ•° (Shannonç†µ): {diversity:.3f}")
        report.append(f"ç†è®ºæœ€å¤§ç†µ: {math.log2(5):.3f} (5ç±»åˆ†ç±»)")
        report.append(f"å¤šæ ·æ€§æ¯”ç‡: {diversity / math.log2(5) * 100:.1f}%")
        
        report_text = "\n".join(report)
        
        if output_file:
            output_path = Path(output_file)
            output_path.write_text(report_text, encoding='utf-8')
            print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report_text

def main():
    """ä¸»å‡½æ•°"""
    stats_generator = ClassificationStatistics(997)
    
    print("æ­£åœ¨ç”ŸæˆT{n}ç†è®ºåˆ†ç±»ç»Ÿè®¡æŠ¥å‘Š...")
    report = stats_generator.generate_report("classification_statistics_report.txt")
    
    print(report)
    
    # ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æ•°æ®
    import json
    detailed_stats = stats_generator.generate_complete_statistics()
    
    with open("classification_statistics_data.json", "w", encoding='utf-8') as f:
        json.dump(detailed_stats, f, indent=2, ensure_ascii=False)
    
    print(f"\nè¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°: classification_statistics_data.json")

if __name__ == "__main__":
    main()