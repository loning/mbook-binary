#!/usr/bin/env python3
"""
Test Suite for M1.7 Theory Predictive Power Metatheorem
Tests the four-type prediction generation framework and prediction quality metrics
"""

import unittest
import math
import numpy as np
from typing import List, Dict, Set, Tuple, Optional, Any, Union
from enum import Enum

# Fibonacci sequence for φ-encoding (F1=1, F2=2, ...)
FIBONACCI = [1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597]
PHI = (1 + math.sqrt(5)) / 2

class PredictionType(Enum):
    """Types of predictions generated by theory"""
    DETERMINISTIC = "deterministic"
    PROBABILISTIC = "probabilistic"
    EMERGENT = "emergent"
    RECURSIVE = "recursive"

class PredictionQuality(Enum):
    """Quality metrics for predictions"""
    ACCURACY = "accuracy"
    PRECISION = "precision"
    NOVELTY = "novelty"
    RANGE = "range"
    ROBUSTNESS = "robustness"

class PredictionStatus(Enum):
    """Status of prediction validation"""
    PENDING = "pending"
    VERIFIED = "verified"
    FALSIFIED = "falsified"
    REVISED = "revised"

class Prediction:
    """Represents a theoretical prediction with φ-encoding properties"""
    def __init__(self, statement: str, prediction_type: PredictionType, 
                 theory_id: str, confidence: float = 0.5):
        self.statement = statement
        self.prediction_type = prediction_type
        self.theory_id = theory_id
        self.confidence = max(0.0, min(1.0, confidence))
        self.zeckendorf_encoding = self._compute_zeckendorf()
        self.status = PredictionStatus.PENDING
        
    def _compute_zeckendorf(self) -> List[int]:
        """Compute Zeckendorf decomposition of statement hash"""
        statement_hash = hash(self.statement) % 1000
        return self._zeckendorf_decompose(statement_hash)
    
    def _zeckendorf_decompose(self, n: int) -> List[int]:
        """Decompose number into non-consecutive Fibonacci numbers"""
        if n <= 0:
            return []
        
        decomposition = []
        i = len(FIBONACCI) - 1
        
        while i >= 0 and n > 0:
            if FIBONACCI[i] <= n:
                decomposition.append(FIBONACCI[i])
                n -= FIBONACCI[i]
                i -= 2  # Skip next to avoid consecutive
            else:
                i -= 1
        
        return sorted(decomposition)
    
    def get_precision_bound(self) -> float:
        """Get precision bound based on Zeckendorf encoding"""
        if not self.zeckendorf_encoding:
            return 1.0
        return PHI ** (-len(self.zeckendorf_encoding))
    
    def update_status(self, status: PredictionStatus):
        """Update prediction status"""
        self.status = status

class TheorySystem:
    """Theory system for predictive power analysis"""
    def __init__(self, name: str, theory_index: int):
        self.name = name
        self.theory_index = theory_index
        self.predictions: List[Prediction] = []
        self.dependencies: List[str] = []
        self.complexity_level = self._compute_complexity_level()
        
    def _compute_complexity_level(self) -> float:
        """Compute theory complexity level from index"""
        zeck = self._zeckendorf_decompose(self.theory_index)
        return len(zeck) + sum(math.log(f + 1) for f in zeck) / 10.0
    
    def _zeckendorf_decompose(self, n: int) -> List[int]:
        """Decompose number into non-consecutive Fibonacci numbers"""
        if n <= 0:
            return []
        
        decomposition = []
        i = len(FIBONACCI) - 1
        
        while i >= 0 and n > 0:
            if FIBONACCI[i] <= n:
                decomposition.append(FIBONACCI[i])
                n -= FIBONACCI[i]
                i -= 2
            else:
                i -= 1
        
        return sorted(decomposition)
    
    def add_prediction(self, prediction: Prediction):
        """Add prediction to theory system"""
        self.predictions.append(prediction)
    
    def add_dependency(self, dependency_theory: str):
        """Add theory dependency"""
        if dependency_theory not in self.dependencies:
            self.dependencies.append(dependency_theory)

class PredictivePowerAnalyzer:
    """Analyzes theory predictive power using four-type framework"""
    
    def __init__(self):
        self.phi = PHI
        self.predictive_power_threshold = PHI ** 10  # φ^10 ≈ 122.99
        
    def generate_deterministic_predictions(self, theory: TheorySystem) -> List[Prediction]:
        """Generate deterministic predictions from theory"""
        predictions = []
        
        # From fold signatures (V1-V5 verification conditions)
        for i, fib in enumerate(self._zeckendorf_decompose(theory.theory_index)):
            if self._verify_fold_signature(fib):
                statement = f"System must satisfy constraint F{FIBONACCI.index(fib)+1} with probability 1.0"
                prediction = Prediction(statement, PredictionType.DETERMINISTIC, 
                                     theory.name, confidence=1.0)
                predictions.append(prediction)
        
        # From tensor structure analysis
        if theory.complexity_level > 2.0:
            structure_prediction = f"Theory exhibits φ-optimized tensor structure at level {theory.complexity_level:.2f}"
            prediction = Prediction(structure_prediction, PredictionType.DETERMINISTIC,
                                  theory.name, confidence=0.95)
            predictions.append(prediction)
        
        # From No-11 constraints
        forbidden_statement = "System cannot encode consecutive 11 patterns"
        forbidden_prediction = Prediction(forbidden_statement, PredictionType.DETERMINISTIC,
                                        theory.name, confidence=1.0)
        predictions.append(forbidden_prediction)
        
        return predictions
    
    def generate_probabilistic_predictions(self, theory: TheorySystem, 
                                         threshold: float = 0.5) -> List[Prediction]:
        """Generate probabilistic predictions with entropy distribution"""
        predictions = []
        
        # Entropy increase probabilities
        entropy_prob = min(0.99, 0.7 + theory.complexity_level * 0.1)
        if entropy_prob > threshold:
            entropy_statement = f"System entropy increases with probability {entropy_prob:.3f}"
            prediction = Prediction(entropy_statement, PredictionType.PROBABILISTIC,
                                  theory.name, confidence=entropy_prob)
            predictions.append(prediction)
        
        # φ-encoding optimization probabilities
        for i, fib in enumerate(self._zeckendorf_decompose(theory.theory_index)):
            opt_prob = max(0.5, 1.0 - i * 0.1)  # Decreasing with Fibonacci index
            if opt_prob > threshold:
                opt_statement = f"F{FIBONACCI.index(fib)+1} optimization occurs with probability {opt_prob:.3f}"
                prediction = Prediction(opt_statement, PredictionType.PROBABILISTIC,
                                      theory.name, confidence=opt_prob)
                predictions.append(prediction)
        
        # Quantum superposition probabilities
        if self._has_quantum_features(theory):
            quantum_prob = 0.75 + theory.complexity_level * 0.05
            quantum_statement = f"Quantum coherence maintained with probability {quantum_prob:.3f}"
            prediction = Prediction(quantum_statement, PredictionType.PROBABILISTIC,
                                  theory.name, confidence=quantum_prob)
            predictions.append(prediction)
        
        return predictions
    
    def generate_emergent_predictions(self, theory: TheorySystem, 
                                    theory_database: List[TheorySystem]) -> List[Prediction]:
        """Generate emergent predictions from theory combinations"""
        predictions = []
        
        # Dual theory emergence
        for other_theory in theory_database:
            if self._theories_compatible(theory, other_theory):
                emergence_statement = f"Combination with {other_theory.name} produces emergent property: "
                emergence_statement += f"φ-coupled dynamics at level {(theory.complexity_level + other_theory.complexity_level) * self.phi:.2f}"
                
                prediction = Prediction(emergence_statement, PredictionType.EMERGENT,
                                      f"{theory.name}⊗{other_theory.name}", confidence=0.7)
                predictions.append(prediction)
        
        # Critical phase transitions
        if theory.complexity_level > PHI ** 2:
            critical_statement = f"Critical phase transition at complexity threshold {theory.complexity_level:.2f}"
            prediction = Prediction(critical_statement, PredictionType.EMERGENT,
                                  theory.name, confidence=0.6)
            predictions.append(prediction)
        
        return predictions
    
    def generate_recursive_predictions(self, theory: TheorySystem, 
                                     max_depth: int = 10) -> List[Prediction]:
        """Generate recursive predictions from self-referential patterns"""
        predictions = []
        
        # Fixed point predictions
        for depth in range(1, min(max_depth, len(theory.dependencies) + 3)):
            fixed_point_statement = f"Self-referential pattern converges to fixed point at depth {depth}"
            prediction = Prediction(fixed_point_statement, PredictionType.RECURSIVE,
                                  theory.name, confidence=max(0.3, 1.0 - depth * 0.1))
            predictions.append(prediction)
        
        # Self-reference cycle predictions  
        if theory.complexity_level > 1.5:
            cycle_statement = f"Self-reference cycle of period {int(theory.complexity_level * self.phi)}"
            prediction = Prediction(cycle_statement, PredictionType.RECURSIVE,
                                  theory.name, confidence=0.6)
            predictions.append(prediction)
        
        # Fractal structure predictions
        if self._has_fractal_structure(theory):
            fractal_statement = f"Fractal self-similarity at scales {self.phi**i:.2f} for i=1,2,3..."
            prediction = Prediction(fractal_statement, PredictionType.RECURSIVE,
                                  theory.name, confidence=0.7)
            predictions.append(prediction)
        
        return predictions
    
    def compute_prediction_quality_tensor(self, predictions: List[Prediction]) -> Dict[str, float]:
        """Compute five-dimensional prediction quality tensor"""
        if not predictions:
            return {quality.value: 0.0 for quality in PredictionQuality}
        
        # Accuracy: verified predictions ratio
        verified_count = sum(1 for p in predictions if p.status == PredictionStatus.VERIFIED)
        accuracy = verified_count / len(predictions)
        
        # Precision: average precision based on Zeckendorf encoding
        precision_scores = [1.0 / (1.0 + len(p.zeckendorf_encoding)) for p in predictions]
        precision = np.mean(precision_scores)
        
        # Novelty: predictions not in baseline theory set
        novelty = self._compute_novelty_score(predictions)
        
        # Range: coverage of prediction domains
        range_score = self._compute_range_score(predictions)
        
        # Robustness: stability under perturbations
        robustness = self._compute_robustness_score(predictions)
        
        return {
            PredictionQuality.ACCURACY.value: max(0.0, min(1.0, accuracy)),
            PredictionQuality.PRECISION.value: max(0.0, min(1.0, precision)),
            PredictionQuality.NOVELTY.value: max(0.0, min(1.0, novelty)),
            PredictionQuality.RANGE.value: max(0.0, min(1.0, range_score)),
            PredictionQuality.ROBUSTNESS.value: max(0.0, min(1.0, robustness))
        }
    
    def compute_prediction_strength(self, predictions: List[Prediction]) -> float:
        """Compute overall prediction strength using φ-weighted sum"""
        quality_tensor = self.compute_prediction_quality_tensor(predictions)
        
        strength = 0.0
        for i, (quality_type, score) in enumerate(quality_tensor.items()):
            weight = self.phi ** i
            strength += weight * score
        
        return strength
    
    def assess_prediction_confidence(self, prediction: Prediction) -> float:
        """Assess prediction confidence using multiple factors"""
        base_confidence = prediction.confidence
        
        # Consistency score with theory
        consistency_score = self._check_theory_consistency(prediction)
        
        # No-11 constraint satisfaction
        no11_score = self._check_no11_compliance(prediction)
        
        # Zeckendorf encoding validity
        zeck_score = 1.0 if prediction.zeckendorf_encoding else 0.0
        
        # Five-fold equivalence (if applicable)
        five_fold_score = self._check_five_fold_equivalence(prediction)
        
        # Meta-theory compatibility
        meta_score = self._check_meta_compatibility(prediction)
        
        # Weighted combination using φ-powers
        weights = [self.phi**i for i in range(5)]
        scores = [consistency_score, no11_score, zeck_score, five_fold_score, meta_score]
        
        weighted_confidence = sum(w * s for w, s in zip(weights, scores)) / sum(weights)
        
        return min(1.0, base_confidence * weighted_confidence)
    
    def is_theory_mature(self, theory: TheorySystem) -> bool:
        """Check if theory meets maturity threshold φ^10 ≈ 122.99"""
        all_predictions = []
        all_predictions.extend(self.generate_deterministic_predictions(theory))
        all_predictions.extend(self.generate_probabilistic_predictions(theory))
        all_predictions.extend(self.generate_emergent_predictions(theory, []))
        all_predictions.extend(self.generate_recursive_predictions(theory))
        
        prediction_strength = self.compute_prediction_strength(all_predictions)
        return prediction_strength >= self.predictive_power_threshold
    
    def enhance_predictions_through_combination(self, theory: TheorySystem,
                                              other_theories: List[TheorySystem]) -> List[Prediction]:
        """Enhance predictions through theory combination"""
        enhanced_predictions = []
        base_predictions = self.generate_deterministic_predictions(theory)
        
        for other in other_theories:
            if self._theories_compatible(theory, other):
                # Enhanced prediction strength
                for pred in base_predictions:
                    enhanced_statement = f"[Enhanced by {other.name}] {pred.statement}"
                    enhanced_conf = min(1.0, pred.confidence * self.phi)
                    enhanced_pred = Prediction(enhanced_statement, pred.prediction_type,
                                             f"{theory.name}⊗{other.name}", enhanced_conf)
                    enhanced_predictions.append(enhanced_pred)
        
        return enhanced_predictions
    
    # Helper methods
    def _verify_fold_signature(self, fibonacci_num: int) -> bool:
        """Verify V1-V5 conditions for Fibonacci number"""
        return fibonacci_num in FIBONACCI and fibonacci_num >= 3
    
    def _zeckendorf_decompose(self, n: int) -> List[int]:
        """Decompose number into Zeckendorf representation"""
        if n <= 0:
            return []
        
        decomposition = []
        i = len(FIBONACCI) - 1
        
        while i >= 0 and n > 0:
            if FIBONACCI[i] <= n:
                decomposition.append(FIBONACCI[i])
                n -= FIBONACCI[i]
                i -= 2
            else:
                i -= 1
        
        return sorted(decomposition)
    
    def _has_quantum_features(self, theory: TheorySystem) -> bool:
        """Check if theory has quantum features"""
        return theory.complexity_level > 1.0 and len(theory.dependencies) >= 2
    
    def _theories_compatible(self, theory1: TheorySystem, theory2: TheorySystem) -> bool:
        """Check if two theories are compatible for combination"""
        return (abs(theory1.complexity_level - theory2.complexity_level) < 2.0 and
                theory1.name != theory2.name)
    
    def _has_fractal_structure(self, theory: TheorySystem) -> bool:
        """Check if theory has fractal recursive structure"""
        zeck = self._zeckendorf_decompose(theory.theory_index)
        return len(zeck) >= 2 and theory.complexity_level > 1.0
    
    def _compute_novelty_score(self, predictions: List[Prediction]) -> float:
        """Compute novelty score for predictions"""
        if not predictions:
            return 0.0
        
        # Based on statement uniqueness and complexity
        unique_patterns = set()
        for pred in predictions:
            pattern = len(pred.zeckendorf_encoding)
            unique_patterns.add(pattern)
        
        return min(1.0, len(unique_patterns) / len(predictions))
    
    def _compute_range_score(self, predictions: List[Prediction]) -> float:
        """Compute range coverage score"""
        if not predictions:
            return 0.0
        
        # Based on prediction type diversity
        type_coverage = len(set(p.prediction_type for p in predictions)) / len(PredictionType)
        return type_coverage
    
    def _compute_robustness_score(self, predictions: List[Prediction]) -> float:
        """Compute robustness score"""
        if not predictions:
            return 0.0
        
        # Based on confidence stability
        confidences = [p.confidence for p in predictions]
        mean_conf = np.mean(confidences)
        std_conf = np.std(confidences) if len(confidences) > 1 else 0.0
        
        return max(0.0, mean_conf - std_conf)
    
    def _check_theory_consistency(self, prediction: Prediction) -> float:
        """Check prediction consistency with theory"""
        return 1.0 if prediction.confidence > 0.3 else 0.5
    
    def _check_no11_compliance(self, prediction: Prediction) -> float:
        """Check No-11 constraint compliance"""
        if not prediction.zeckendorf_encoding:
            return 1.0
        
        # Check for consecutive Fibonacci numbers
        for i in range(len(prediction.zeckendorf_encoding) - 1):
            current_idx = FIBONACCI.index(prediction.zeckendorf_encoding[i])
            next_idx = FIBONACCI.index(prediction.zeckendorf_encoding[i + 1])
            if next_idx == current_idx + 1:
                return 0.0
        
        return 1.0
    
    def _check_five_fold_equivalence(self, prediction: Prediction) -> float:
        """Check five-fold equivalence if applicable"""
        if "complexity" in prediction.statement.lower():
            return 0.9
        return 0.7
    
    def _check_meta_compatibility(self, prediction: Prediction) -> float:
        """Check meta-theory compatibility"""
        if ("entropy" in prediction.statement.lower() or 
            "φ" in prediction.statement or
            "fibonacci" in prediction.statement.lower()):
            return 0.95
        return 0.8

class TestM17TheoryPredictivePower(unittest.TestCase):
    """Test suite for M1.7 Theory Predictive Power Metatheorem"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.analyzer = PredictivePowerAnalyzer()
        self.phi = PHI
        
        # Create test theory systems
        self.test_theory = TheorySystem("T13_TestTheory", 13)  # F7 = 13
        self.test_theory.add_dependency("T1")
        self.test_theory.add_dependency("T8")
        
        self.complex_theory = TheorySystem("T89_ComplexTheory", 89)  # F11 = 89
        self.complex_theory.add_dependency("T1")
        self.complex_theory.add_dependency("T21")
        self.complex_theory.add_dependency("T34")
        
        # Database of theories for emergence testing
        self.theory_database = [
            TheorySystem("T5_SimpleTheory", 5),
            TheorySystem("T21_MidTheory", 21),
            TheorySystem("T34_AdvancedTheory", 34)
        ]
    
    def test_prediction_zeckendorf_encoding(self):
        """Test Zeckendorf encoding for predictions"""
        prediction = Prediction("Test prediction statement", PredictionType.DETERMINISTIC, "T_test")
        
        # Should have valid Zeckendorf decomposition
        self.assertIsInstance(prediction.zeckendorf_encoding, list)
        self.assertTrue(all(fib in FIBONACCI for fib in prediction.zeckendorf_encoding))
        
        # Should be sorted
        self.assertEqual(prediction.zeckendorf_encoding, sorted(prediction.zeckendorf_encoding))
    
    def test_prediction_precision_bounds(self):
        """Test precision bound calculation for predictions"""
        prediction = Prediction("Precision test prediction", PredictionType.PROBABILISTIC, "T_test")
        precision_bound = prediction.get_precision_bound()
        
        # Precision should follow φ^(-k) pattern
        expected_bound = self.phi ** (-len(prediction.zeckendorf_encoding))
        self.assertAlmostEqual(precision_bound, expected_bound, places=10)
    
    def test_theory_complexity_computation(self):
        """Test theory complexity level computation"""
        # Simple theory should have low complexity
        simple_theory = TheorySystem("T2_Simple", 2)
        self.assertGreater(simple_theory.complexity_level, 0.0)
        
        # Complex theory should have higher complexity
        self.assertGreater(self.complex_theory.complexity_level, self.test_theory.complexity_level)
    
    def test_deterministic_prediction_generation(self):
        """Test deterministic prediction generation"""
        predictions = self.analyzer.generate_deterministic_predictions(self.test_theory)
        
        # Should generate valid deterministic predictions
        self.assertIsInstance(predictions, list)
        self.assertTrue(all(isinstance(p, Prediction) for p in predictions))
        self.assertTrue(all(p.prediction_type == PredictionType.DETERMINISTIC for p in predictions))
        
        # Should include No-11 constraint prediction
        no11_predictions = [p for p in predictions if "consecutive 11" in p.statement]
        self.assertTrue(len(no11_predictions) > 0)
    
    def test_probabilistic_prediction_generation(self):
        """Test probabilistic prediction generation"""
        predictions = self.analyzer.generate_probabilistic_predictions(self.test_theory)
        
        # Should generate valid probabilistic predictions
        self.assertIsInstance(predictions, list)
        self.assertTrue(all(isinstance(p, Prediction) for p in predictions))
        self.assertTrue(all(p.prediction_type == PredictionType.PROBABILISTIC for p in predictions))
        
        # Should include entropy predictions
        entropy_predictions = [p for p in predictions if "entropy" in p.statement]
        self.assertTrue(len(entropy_predictions) > 0)
    
    def test_emergent_prediction_generation(self):
        """Test emergent prediction generation"""
        predictions = self.analyzer.generate_emergent_predictions(self.test_theory, self.theory_database)
        
        # Should generate valid emergent predictions
        self.assertIsInstance(predictions, list)
        self.assertTrue(all(isinstance(p, Prediction) for p in predictions))
        self.assertTrue(all(p.prediction_type == PredictionType.EMERGENT for p in predictions))
    
    def test_recursive_prediction_generation(self):
        """Test recursive prediction generation"""
        predictions = self.analyzer.generate_recursive_predictions(self.test_theory)
        
        # Should generate valid recursive predictions
        self.assertIsInstance(predictions, list)
        self.assertTrue(all(isinstance(p, Prediction) for p in predictions))
        self.assertTrue(all(p.prediction_type == PredictionType.RECURSIVE for p in predictions))
    
    def test_prediction_quality_tensor_computation(self):
        """Test prediction quality tensor computation"""
        # Generate test predictions
        predictions = []
        predictions.extend(self.analyzer.generate_deterministic_predictions(self.test_theory))
        predictions.extend(self.analyzer.generate_probabilistic_predictions(self.test_theory))
        
        quality_tensor = self.analyzer.compute_prediction_quality_tensor(predictions)
        
        # Should have all five quality dimensions
        expected_keys = {q.value for q in PredictionQuality}
        self.assertEqual(set(quality_tensor.keys()), expected_keys)
        
        # All values should be in [0,1]
        for value in quality_tensor.values():
            self.assertGreaterEqual(value, 0.0)
            self.assertLessEqual(value, 1.0)
    
    def test_prediction_strength_computation(self):
        """Test prediction strength computation"""
        # Generate test predictions
        predictions = []
        predictions.extend(self.analyzer.generate_deterministic_predictions(self.test_theory))
        predictions.extend(self.analyzer.generate_probabilistic_predictions(self.test_theory))
        
        strength = self.analyzer.compute_prediction_strength(predictions)
        
        # Strength should be non-negative
        self.assertGreaterEqual(strength, 0.0)
        self.assertIsInstance(strength, float)
    
    def test_prediction_confidence_assessment(self):
        """Test prediction confidence assessment"""
        prediction = Prediction("High confidence test prediction", 
                               PredictionType.DETERMINISTIC, "T_test", confidence=0.9)
        
        assessed_confidence = self.analyzer.assess_prediction_confidence(prediction)
        
        # Assessed confidence should be in [0,1]
        self.assertGreaterEqual(assessed_confidence, 0.0)
        self.assertLessEqual(assessed_confidence, 1.0)
        self.assertIsInstance(assessed_confidence, float)
    
    def test_theory_maturity_assessment(self):
        """Test theory maturity assessment"""
        is_mature = self.analyzer.is_theory_mature(self.complex_theory)
        
        # Should return boolean (convert numpy bool to Python bool)
        self.assertIsInstance(bool(is_mature), bool)
        
        # Check threshold value
        self.assertAlmostEqual(self.analyzer.predictive_power_threshold, self.phi ** 10, places=5)
    
    def test_prediction_enhancement_through_combination(self):
        """Test prediction enhancement through theory combination"""
        enhanced = self.analyzer.enhance_predictions_through_combination(
            self.test_theory, self.theory_database
        )
        
        # Should generate enhanced predictions
        self.assertIsInstance(enhanced, list)
        self.assertTrue(all(isinstance(p, Prediction) for p in enhanced))
    
    def test_fold_signature_verification(self):
        """Test V1-V5 fold signature verification"""
        # Test with valid Fibonacci numbers
        self.assertTrue(self.analyzer._verify_fold_signature(5))
        self.assertTrue(self.analyzer._verify_fold_signature(13))
        
        # Test with invalid numbers
        self.assertFalse(self.analyzer._verify_fold_signature(1))  # Too small
        self.assertFalse(self.analyzer._verify_fold_signature(7))  # Not Fibonacci
    
    def test_theory_compatibility_checking(self):
        """Test theory compatibility for combinations"""
        # Similar complexity theories should be compatible
        theory1 = TheorySystem("T8_Test1", 8)
        theory2 = TheorySystem("T13_Test2", 13)
        
        self.assertTrue(self.analyzer._theories_compatible(theory1, theory2))
        
        # Same theory should not be compatible with itself
        self.assertFalse(self.analyzer._theories_compatible(theory1, theory1))
    
    def test_quantum_features_detection(self):
        """Test quantum features detection in theories"""
        # Complex theory with dependencies should have quantum features
        # The complex_theory (T89) has 3 dependencies already from setUp
        self.assertTrue(self.analyzer._has_quantum_features(self.complex_theory))
        
        # Simple theory should not have quantum features
        simple_theory = TheorySystem("T2_Simple", 2)
        self.assertFalse(self.analyzer._has_quantum_features(simple_theory))
    
    def test_fractal_structure_detection(self):
        """Test fractal structure detection"""
        # Test with a number that has multiple Fibonacci components
        # Use 100 = 89 + 8 + 3 (F11 + F6 + F4) - has length 3 Zeckendorf decomposition
        fractal_theory = TheorySystem("T100_Fractal", 100) 
        self.assertTrue(self.analyzer._has_fractal_structure(fractal_theory))
        
        # Simple theory should not have fractal structure
        simple_theory = TheorySystem("T3_Simple", 3)
        self.assertFalse(self.analyzer._has_fractal_structure(simple_theory))
    
    def test_no11_constraint_compliance(self):
        """Test No-11 constraint compliance checking"""
        # Create prediction with non-consecutive Fibonacci encoding
        good_prediction = Prediction("Good prediction", PredictionType.DETERMINISTIC, "T_test")
        good_prediction.zeckendorf_encoding = [2, 8, 21]  # Non-consecutive Fibonacci
        
        compliance_score = self.analyzer._check_no11_compliance(good_prediction)
        self.assertEqual(compliance_score, 1.0)
        
        # Create prediction that would violate No-11 (consecutive Fibonacci)
        bad_prediction = Prediction("Bad prediction", PredictionType.DETERMINISTIC, "T_test")
        bad_prediction.zeckendorf_encoding = [3, 5]  # F3 and F4 are consecutive
        
        violation_score = self.analyzer._check_no11_compliance(bad_prediction)
        self.assertEqual(violation_score, 0.0)
    
    def test_four_type_prediction_completeness(self):
        """Test that four prediction types cover all possibilities"""
        all_predictions = []
        all_predictions.extend(self.analyzer.generate_deterministic_predictions(self.test_theory))
        all_predictions.extend(self.analyzer.generate_probabilistic_predictions(self.test_theory))
        all_predictions.extend(self.analyzer.generate_emergent_predictions(self.test_theory, self.theory_database))
        all_predictions.extend(self.analyzer.generate_recursive_predictions(self.test_theory))
        
        # Should cover all four prediction types
        prediction_types = {p.prediction_type for p in all_predictions}
        
        # Check that we have deterministic predictions (always generated)
        self.assertIn(PredictionType.DETERMINISTIC, prediction_types)
    
    def test_phi_weighted_quality_computation(self):
        """Test φ-weighted quality computation"""
        # Create test predictions
        predictions = [
            Prediction("Test 1", PredictionType.DETERMINISTIC, "T_test", 0.9),
            Prediction("Test 2", PredictionType.PROBABILISTIC, "T_test", 0.8)
        ]
        
        # Set one as verified for accuracy testing
        predictions[0].update_status(PredictionStatus.VERIFIED)
        
        quality_tensor = self.analyzer.compute_prediction_quality_tensor(predictions)
        strength = self.analyzer.compute_prediction_strength(predictions)
        
        # Strength should be φ-weighted sum
        expected_strength = sum(self.phi**i * score 
                              for i, score in enumerate(quality_tensor.values()))
        self.assertAlmostEqual(strength, expected_strength, places=5)
    
    def test_prediction_status_management(self):
        """Test prediction status management"""
        prediction = Prediction("Status test", PredictionType.DETERMINISTIC, "T_test")
        
        # Initial status should be pending
        self.assertEqual(prediction.status, PredictionStatus.PENDING)
        
        # Should be able to update status
        prediction.update_status(PredictionStatus.VERIFIED)
        self.assertEqual(prediction.status, PredictionStatus.VERIFIED)
    
    def test_empty_prediction_handling(self):
        """Test handling of empty prediction sets"""
        empty_predictions = []
        
        quality_tensor = self.analyzer.compute_prediction_quality_tensor(empty_predictions)
        strength = self.analyzer.compute_prediction_strength(empty_predictions)
        
        # Should handle empty predictions gracefully
        self.assertEqual(strength, 0.0)
        self.assertTrue(all(score == 0.0 for score in quality_tensor.values()))
    
    def test_prediction_confidence_bounds(self):
        """Test that prediction confidence is properly bounded"""
        # Test confidence clamping
        high_conf_pred = Prediction("High conf", PredictionType.DETERMINISTIC, "T_test", 1.5)
        low_conf_pred = Prediction("Low conf", PredictionType.DETERMINISTIC, "T_test", -0.5)
        
        self.assertEqual(high_conf_pred.confidence, 1.0)
        self.assertEqual(low_conf_pred.confidence, 0.0)
        
        # Test assessed confidence bounds
        assessed_high = self.analyzer.assess_prediction_confidence(high_conf_pred)
        assessed_low = self.analyzer.assess_prediction_confidence(low_conf_pred)
        
        self.assertLessEqual(assessed_high, 1.0)
        self.assertGreaterEqual(assessed_low, 0.0)

if __name__ == '__main__':
    unittest.main()