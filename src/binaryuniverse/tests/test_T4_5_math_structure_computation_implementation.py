#!/usr/bin/env python3
"""
T4.5 æ•°å­¦ç»“æ„è®¡ç®—å®ç°å®šç† - å®Œæ•´æµ‹è¯•å¥—ä»¶
åŸºäºä¸¥æ ¼çš„Ï†-ç¼–ç å’ŒNo-11çº¦æŸéªŒè¯æ•°å­¦ç»“æ„çš„è®¡ç®—å®ç°

æµ‹è¯•è¦†ç›–ï¼š
1. æ•°å­¦ç»“æ„çš„è®¡ç®—è¡¨ç¤ºå®Œæ•´æ€§
2. Ï†-å¤æ‚åº¦ç±»çš„æ­£ç¡®åˆ†çº§
3. ç»“æ„ç­‰ä»·è®¡ç®—çš„éªŒè¯
4. ç®—æ³•å¤æ‚åº¦ç•Œé™çš„éªŒè¯
5. ç»“æ„ä¿çœŸåº¦çš„ä¿æŒ
6. é€’å½’å®Œå¤‡æ€§çš„å®ç°
7. è®¡ç®—è¿‡ç¨‹çš„ç†µå¢æ€§è´¨
8. è‡ªæˆ‘å®ç°ç³»ç»Ÿçš„ç¨³å®šæ€§
"""

import unittest
import numpy as np
import cmath
from typing import List, Dict, Tuple, Set, Optional, Union, Callable, Any
from dataclasses import dataclass, field
import math
from numbers import Complex
from enum import Enum
import time
import inspect

# å¯¼å…¥åŸºç¡€Zeckendorfç¼–ç ç±»
from zeckendorf_base import ZeckendorfInt, PhiConstant, EntropyValidator

# å¯¼å…¥T3.6çš„æ•°å­¦ç»“æ„ç±»
from test_T3_6_quantum_math_structure_emergence import (
    AlgebraicStructure, TopologicalStructure, GeometricStructure,
    CategoricalStructure, HomotopicStructure, MathStructureLevel,
    QuantumMathEmergence
)


class PhiComplexityClass(Enum):
    """Ï†-å¤æ‚åº¦ç±»æšä¸¾"""
    PHI_P = "P"          # |S| = 1 çš„å¤šé¡¹å¼æ—¶é—´
    PHI_NP = "NP"        # |S| = 2 çš„éç¡®å®šæ€§å¤šé¡¹å¼æ—¶é—´  
    PHI_EXP = "EXP"      # |S| â‰¥ 3 çš„æŒ‡æ•°æ—¶é—´
    PHI_REC = "REC"      # |S| = F_n çš„é€’å½’å¯æšä¸¾


@dataclass
class ComputationalAlgorithm:
    """è®¡ç®—ç®—æ³•çš„è¡¨ç¤º"""
    name: str
    function: Callable = field(default=lambda x: x)
    complexity_bound: float = field(default=1.0)
    preserves_no11: bool = field(default=True)
    input_types: List[type] = field(default_factory=list)
    output_type: type = field(default=object)
    
    def execute(self, *args, **kwargs):
        """æ‰§è¡Œç®—æ³•"""
        if not self.preserves_no11:
            raise ValueError(f"Algorithm {self.name} violates No-11 constraint")
        
        # éªŒè¯è¾“å…¥ç±»å‹
        if self.input_types:
            for i, (arg, expected_type) in enumerate(zip(args, self.input_types)):
                if not isinstance(arg, expected_type):
                    raise TypeError(f"Argument {i} expected {expected_type}, got {type(arg)}")
        
        return self.function(*args, **kwargs)
    
    def compute_complexity(self, input_size: int) -> float:
        """è®¡ç®—ç®—æ³•å¤æ‚åº¦"""
        phi = PhiConstant.phi()
        return self.complexity_bound * (phi ** math.log(input_size, phi))


@dataclass
class ZeckendorfData:
    """Zeckendorfç¼–ç çš„æ•°æ®è¡¨ç¤º"""
    indices: Set[int] = field(default_factory=set)
    values: Dict[int, Complex] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        """éªŒè¯æ•°æ®çš„æœ‰æ•ˆæ€§"""
        self._validate_no11_constraint()
        self._validate_zeckendorf_encoding()
    
    def _validate_no11_constraint(self):
        """éªŒè¯No-11çº¦æŸ"""
        indices_list = sorted(self.indices)
        for i in range(len(indices_list) - 1):
            if indices_list[i+1] - indices_list[i] == 1:
                raise ValueError(f"No-11 constraint violation: consecutive indices {indices_list[i]} and {indices_list[i+1]}")
    
    def _validate_zeckendorf_encoding(self):
        """éªŒè¯Zeckendorfç¼–ç çš„æœ‰æ•ˆæ€§"""
        for idx in self.indices:
            if idx < 0:  # åªæ‹’ç»è´Ÿæ•°ç´¢å¼•ï¼Œå…è®¸0
                raise ValueError(f"Invalid Fibonacci index: {idx}")
    
    def compute_entropy(self) -> float:
        """è®¡ç®—æ•°æ®ç†µ"""
        if not self.indices:
            return 0.0
        
        # åŸºäºFibonacciç»“æ„å’Œå€¼åˆ†å¸ƒçš„ç†µ
        structure_entropy = math.log2(len(self.indices) + 1)
        
        if self.values:
            # å€¼åˆ†å¸ƒçš„ä¿¡æ¯ç†µ
            probabilities = [abs(val)**2 for val in self.values.values()]
            total_prob = sum(probabilities)
            
            if total_prob > 1e-10:
                probabilities = [p / total_prob for p in probabilities]
                value_entropy = -sum(p * math.log2(p) for p in probabilities if p > 1e-10)
            else:
                value_entropy = 0.0
        else:
            value_entropy = 0.0
        
        return structure_entropy + value_entropy
    
    def size(self) -> int:
        """è®¡ç®—æ•°æ®å¤§å°"""
        return len(self.indices) + len(self.values) + len(self.metadata)


@dataclass
class ComputationalOperator:
    """è®¡ç®—ç®—å­"""
    name: str
    operation: Callable
    domain: Set[int] = field(default_factory=set)
    codomain: Set[int] = field(default_factory=set)
    preserves_structure: bool = field(default=True)
    
    def apply(self, data: ZeckendorfData) -> ZeckendorfData:
        """åº”ç”¨ç®—å­åˆ°æ•°æ®"""
        if not self.preserves_structure:
            raise ValueError(f"Operator {self.name} does not preserve structure")
        
        # æ£€æŸ¥å®šä¹‰åŸŸ
        if self.domain and not self.domain.issubset(data.indices):
            raise ValueError(f"Data indices not in operator domain")
        
        result_values = {}
        for k, v in data.values.items():
            if k in data.indices:
                result_values[k] = self.operation(v)
        
        # æ„é€ ç»“æœï¼Œç¡®ä¿ä¿æŒNo-11çº¦æŸ
        result_indices = self._ensure_no11_constraint(set(result_values.keys()))
        
        return ZeckendorfData(
            indices=result_indices,
            values={k: v for k, v in result_values.items() if k in result_indices},
            metadata={"operator_applied": self.name, "preserves_structure": True}
        )
    
    def _ensure_no11_constraint(self, indices: Set[int]) -> Set[int]:
        """ç¡®ä¿ç´¢å¼•é›†åˆæ»¡è¶³No-11çº¦æŸ"""
        sorted_indices = sorted(indices)
        result = set()
        
        i = 0
        while i < len(sorted_indices):
            current = sorted_indices[i]
            result.add(current)
            
            # è·³è¿‡è¿ç»­çš„ç´¢å¼•
            while i + 1 < len(sorted_indices) and sorted_indices[i+1] == current + 1:
                i += 1
                current = sorted_indices[i]
            
            i += 1
        
        return result


@dataclass
class RecursiveRelation:
    """é€’å½’å…³ç³»"""
    name: str
    base_cases: Dict[int, Any] = field(default_factory=dict)
    recursive_rule: Callable = field(default=lambda n, prev: prev.get(n-1, 0))
    max_depth: int = field(default=100)
    memoization: Dict[int, Any] = field(default_factory=dict)
    
    def compute(self, n: int) -> Any:
        """è®¡ç®—é€’å½’å…³ç³»çš„å€¼"""
        if n in self.memoization:
            return self.memoization[n]
        
        if n in self.base_cases:
            result = self.base_cases[n]
        elif n <= 0:
            result = 0
        elif len(self.memoization) >= self.max_depth:
            # é˜²æ­¢æ— é™é€’å½’
            result = self.base_cases.get(1, 0)
        else:
            result = self.recursive_rule(n, self.memoization)
        
        self.memoization[n] = result
        return result
    
    def is_well_founded(self) -> bool:
        """æ£€æŸ¥é€’å½’å…³ç³»æ˜¯å¦è‰¯åŸº"""
        # ç®€åŒ–æ£€æŸ¥ï¼šéªŒè¯åŸºç¡€æƒ…å†µå­˜åœ¨ä¸”é€’å½’è§„åˆ™æ”¶æ•›
        return len(self.base_cases) > 0 and self.max_depth > 0


@dataclass
class MathStructureImplementation:
    """æ•°å­¦ç»“æ„çš„è®¡ç®—å®ç°"""
    structure_type: MathStructureLevel
    algorithms: List[ComputationalAlgorithm] = field(default_factory=list)
    data: ZeckendorfData = field(default_factory=ZeckendorfData)
    operators: List[ComputationalOperator] = field(default_factory=list)
    relations: List[RecursiveRelation] = field(default_factory=list)
    complexity_class: PhiComplexityClass = field(default=PhiComplexityClass.PHI_P)
    fidelity_score: float = field(default=1.0)
    
    def __post_init__(self):
        """éªŒè¯å®ç°çš„æœ‰æ•ˆæ€§"""
        self._validate_implementation()
    
    def _validate_implementation(self):
        """éªŒè¯å®ç°çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯ç®—æ³•ä¿æŒNo-11çº¦æŸ
        for alg in self.algorithms:
            if not alg.preserves_no11:
                raise ValueError(f"Algorithm {alg.name} violates No-11 constraint")
        
        # éªŒè¯ç®—å­ä¿æŒç»“æ„
        for op in self.operators:
            if not op.preserves_structure:
                raise ValueError(f"Operator {op.name} does not preserve structure")
        
        # éªŒè¯é€’å½’å…³ç³»çš„è‰¯åŸºæ€§
        for rel in self.relations:
            if not rel.is_well_founded():
                raise ValueError(f"Recursive relation {rel.name} is not well-founded")
    
    def execute_algorithm(self, algorithm_name: str, *args, **kwargs):
        """æ‰§è¡ŒæŒ‡å®šçš„ç®—æ³•"""
        for alg in self.algorithms:
            if alg.name == algorithm_name:
                return alg.execute(*args, **kwargs)
        raise ValueError(f"Algorithm {algorithm_name} not found")
    
    def apply_operator(self, operator_name: str, data: ZeckendorfData) -> ZeckendorfData:
        """åº”ç”¨æŒ‡å®šçš„ç®—å­"""
        for op in self.operators:
            if op.name == operator_name:
                return op.apply(data)
        raise ValueError(f"Operator {operator_name} not found")
    
    def compute_relation(self, relation_name: str, n: int):
        """è®¡ç®—æŒ‡å®šçš„é€’å½’å…³ç³»"""
        for rel in self.relations:
            if rel.name == relation_name:
                return rel.compute(n)
        raise ValueError(f"Recursive relation {relation_name} not found")
    
    def compute_total_complexity(self) -> float:
        """è®¡ç®—æ€»çš„è®¡ç®—å¤æ‚åº¦"""
        algorithm_complexity = sum(alg.complexity_bound for alg in self.algorithms)
        data_complexity = self.data.size()
        operator_complexity = len(self.operators)
        relation_complexity = sum(rel.max_depth for rel in self.relations)
        
        phi = PhiConstant.phi()
        level_factor = phi ** self.structure_type.value
        
        return level_factor * (algorithm_complexity + data_complexity + operator_complexity + relation_complexity)
    
    def compute_structure_entropy(self) -> float:
        """è®¡ç®—ç»“æ„ç†µ"""
        data_entropy = self.data.compute_entropy()
        algorithm_entropy = math.log2(len(self.algorithms) + 1)
        operator_entropy = math.log2(len(self.operators) + 1)
        relation_entropy = math.log2(len(self.relations) + 1)
        
        return data_entropy + algorithm_entropy + operator_entropy + relation_entropy


class StructureComputationConverter:
    """æ•°å­¦ç»“æ„åˆ°è®¡ç®—å®ç°çš„è½¬æ¢å™¨"""
    
    def __init__(self):
        self.phi = PhiConstant.phi()
        self.entropy_validator = EntropyValidator()
    
    def convert_algebraic_structure(self, algebraic: AlgebraicStructure) -> MathStructureImplementation:
        """å°†ä»£æ•°ç»“æ„è½¬æ¢ä¸ºè®¡ç®—å®ç°"""
        # åˆ›å»ºå‘é‡ç©ºé—´ç®—æ³•
        vector_space_alg = ComputationalAlgorithm(
            name="vector_space_operations",
            function=lambda basis, coeffs: self._compute_linear_combination(basis, coeffs),
            complexity_bound=math.log(len(algebraic.vector_space_basis), self.phi),
            input_types=[set, dict]
        )
        
        # åˆ›å»ºå†…ç§¯ç®—æ³•
        inner_product_alg = ComputationalAlgorithm(
            name="phi_inner_product",
            function=lambda v1, v2: self._compute_phi_inner_product(v1, v2),
            complexity_bound=math.log(len(algebraic.vector_space_basis), self.phi),
            input_types=[dict, dict]
        )
        
        # åˆ›å»ºLieæ‹¬å·ç®—æ³•
        lie_bracket_alg = ComputationalAlgorithm(
            name="lie_bracket",
            function=lambda X, Y: self._compute_lie_bracket(X, Y),
            complexity_bound=(math.log(len(algebraic.vector_space_basis), self.phi))**2,
            input_types=[dict, dict]
        )
        
        # åˆ›å»ºæ•°æ®è¡¨ç¤º
        data = ZeckendorfData(
            indices=algebraic.vector_space_basis,
            values={k: complex(1.0, 0.0) for k in algebraic.vector_space_basis},
            metadata={"type": "algebraic", "dimension": len(algebraic.vector_space_basis)}
        )
        
        # åˆ›å»ºç®—å­
        linear_operator = ComputationalOperator(
            name="linear_transformation",
            operation=lambda x: x * self.phi,
            domain=algebraic.vector_space_basis,
            codomain=algebraic.vector_space_basis
        )
        
        return MathStructureImplementation(
            structure_type=MathStructureLevel.ALGEBRAIC,
            algorithms=[vector_space_alg, inner_product_alg, lie_bracket_alg],
            data=data,
            operators=[linear_operator],
            complexity_class=self._classify_phi_complexity(len(algebraic.vector_space_basis))
        )
    
    def convert_topological_structure(self, topological: TopologicalStructure) -> MathStructureImplementation:
        """å°†æ‹“æ‰‘ç»“æ„è½¬æ¢ä¸ºè®¡ç®—å®ç°"""
        # åˆ›å»ºæ‹“æ‰‘ä¸å˜é‡è®¡ç®—ç®—æ³•
        invariant_alg = ComputationalAlgorithm(
            name="topological_invariant_computation",
            function=lambda amplitudes, n: self._compute_topological_invariant(amplitudes, n),
            complexity_bound=len(topological.topological_invariants) * math.log(len(topological.topological_invariants) + 1, self.phi),
            input_types=[dict, int]
        )
        
        # åˆ›å»ºåŒè°ƒç¾¤è®¡ç®—ç®—æ³•
        homology_alg = ComputationalAlgorithm(
            name="homology_computation",
            function=lambda groups: self._compute_betti_numbers(groups),
            complexity_bound=len(topological.homology_groups) * self.phi,
            input_types=[dict]
        )
        
        # åˆ›å»ºæ•°æ®è¡¨ç¤º
        indices = set(topological.topological_invariants.keys()) | set(topological.homology_groups.keys())
        data = ZeckendorfData(
            indices=self._ensure_no11_indices(indices),
            values={k: complex(v, 0) for k, v in topological.topological_invariants.items()},
            metadata={"type": "topological", "fiber_bundle": topological.fiber_bundle_data}
        )
        
        return MathStructureImplementation(
            structure_type=MathStructureLevel.TOPOLOGICAL,
            algorithms=[invariant_alg, homology_alg],
            data=data,
            complexity_class=self._classify_phi_complexity(len(indices))
        )
    
    def convert_geometric_structure(self, geometric: GeometricStructure) -> MathStructureImplementation:
        """å°†å‡ ä½•ç»“æ„è½¬æ¢ä¸ºè®¡ç®—å®ç°"""
        # åˆ›å»ºåº¦é‡è®¡ç®—ç®—æ³•
        metric_alg = ComputationalAlgorithm(
            name="riemann_metric_computation",
            function=lambda g_matrix: self._compute_metric_properties(g_matrix),
            complexity_bound=len(geometric.riemann_metric) * math.log(len(geometric.riemann_metric), self.phi),
            input_types=[dict]
        )
        
        # åˆ›å»ºæ›²ç‡è®¡ç®—ç®—æ³•
        curvature_alg = ComputationalAlgorithm(
            name="curvature_computation",
            function=lambda tensor: self._compute_curvature_invariants(tensor),
            complexity_bound=len(geometric.curvature_tensor) * (self.phi ** 2),
            input_types=[dict]
        )
        
        # åˆ›å»ºæ•°æ®è¡¨ç¤º
        all_indices = set()
        for (i, j) in geometric.riemann_metric.keys():
            all_indices.update([i, j])
        
        data = ZeckendorfData(
            indices=self._ensure_no11_indices(all_indices),
            values={k: complex(1.0, 0.0) for k in all_indices},
            metadata={"type": "geometric", "metric_signature": len(geometric.riemann_metric)}
        )
        
        return MathStructureImplementation(
            structure_type=MathStructureLevel.GEOMETRIC,
            algorithms=[metric_alg, curvature_alg],
            data=data,
            complexity_class=self._classify_phi_complexity(len(all_indices))
        )
    
    def convert_categorical_structure(self, categorical: CategoricalStructure) -> MathStructureImplementation:
        """å°†èŒƒç•´ç»“æ„è½¬æ¢ä¸ºè®¡ç®—å®ç°"""
        # åˆ›å»ºæ€å°„å¤åˆç®—æ³•
        composition_alg = ComputationalAlgorithm(
            name="morphism_composition",
            function=lambda f, g: self._compose_morphisms(f, g),
            complexity_bound=len(categorical.morphisms) * math.log(len(categorical.objects), self.phi),
            input_types=[str, str]
        )
        
        # åˆ›å»ºé«˜é˜¶èŒƒç•´ç®—æ³•
        higher_category_alg = ComputationalAlgorithm(
            name="higher_category_construction",
            function=lambda level: self._construct_n_category(level, categorical.objects),
            complexity_bound=max(categorical.higher_morphisms.keys(), default=1) * (self.phi ** 2),
            input_types=[int]
        )
        
        # åˆ›å»ºæ•°æ®è¡¨ç¤º
        data = ZeckendorfData(
            indices=self._ensure_no11_indices(categorical.objects),
            values={k: complex(1.0, 0.0) for k in categorical.objects},
            metadata={"type": "categorical", "morphism_count": len(categorical.morphisms)}
        )
        
        return MathStructureImplementation(
            structure_type=MathStructureLevel.CATEGORICAL,
            algorithms=[composition_alg, higher_category_alg],
            data=data,
            complexity_class=self._classify_phi_complexity(len(categorical.objects))
        )
    
    def convert_homotopic_structure(self, homotopic: HomotopicStructure) -> MathStructureImplementation:
        """å°†åŒä¼¦ç»“æ„è½¬æ¢ä¸ºè®¡ç®—å®ç°"""
        # åˆ›å»ºåŸºæœ¬ç¾¤è®¡ç®—ç®—æ³•
        fundamental_group_alg = ComputationalAlgorithm(
            name="fundamental_group_computation",
            function=lambda generators: self._compute_group_relations(generators),
            complexity_bound=len(homotopic.fundamental_group) * math.log(len(homotopic.fundamental_group) + 1, self.phi),
            input_types=[set]
        )
        
        # åˆ›å»ºè°±åºåˆ—ç®—æ³•
        spectral_sequence_alg = ComputationalAlgorithm(
            name="spectral_sequence_computation",
            function=lambda sequence_data: self._compute_spectral_sequence(sequence_data),
            complexity_bound=len(homotopic.spectral_sequence) * (self.phi ** 3),
            input_types=[dict]
        )
        
        # åˆ›å»ºæ•°æ®è¡¨ç¤º
        all_indices = set()
        for group_elements in homotopic.higher_homotopy_groups.values():
            all_indices.update(range(1, len(group_elements) + 1))
        
        data = ZeckendorfData(
            indices=self._ensure_no11_indices(all_indices) if all_indices else {2, 5},
            values={k: complex(1.0, 0.0) for k in (all_indices if all_indices else {2, 5})},
            metadata={"type": "homotopic", "fundamental_group_size": len(homotopic.fundamental_group)}
        )
        
        return MathStructureImplementation(
            structure_type=MathStructureLevel.HOMOTOPIC,
            algorithms=[fundamental_group_alg, spectral_sequence_alg],
            data=data,
            complexity_class=self._classify_phi_complexity(len(all_indices) if all_indices else 2)
        )
    
    def _ensure_no11_indices(self, indices: Set[int]) -> Set[int]:
        """ç¡®ä¿ç´¢å¼•é›†åˆæ»¡è¶³No-11çº¦æŸ"""
        if not indices:
            return {2}  # é»˜è®¤å®‰å…¨ç´¢å¼•
        
        sorted_indices = sorted(indices)
        result = set()
        
        i = 0
        while i < len(sorted_indices):
            current = sorted_indices[i]
            result.add(current)
            
            # è·³è¿‡è¿ç»­çš„ç´¢å¼•
            while i + 1 < len(sorted_indices) and sorted_indices[i+1] == current + 1:
                i += 1
            
            i += 1
        
        return result if result else {2}
    
    def _classify_phi_complexity(self, size: int) -> PhiComplexityClass:
        """åˆ†ç±»Ï†-å¤æ‚åº¦"""
        if size <= 1:
            return PhiComplexityClass.PHI_P
        elif size == 2:
            return PhiComplexityClass.PHI_NP
        elif size <= 10:
            return PhiComplexityClass.PHI_EXP
        else:
            return PhiComplexityClass.PHI_REC
    
    def _compute_linear_combination(self, basis: set, coeffs: dict) -> dict:
        """è®¡ç®—çº¿æ€§ç»„åˆ"""
        result = {}
        for k in basis:
            if k in coeffs:
                result[k] = coeffs[k]
        return result
    
    def _compute_phi_inner_product(self, v1: dict, v2: dict) -> complex:
        """è®¡ç®—Ï†-å†…ç§¯"""
        result = 0.0 + 0.0j
        common_keys = set(v1.keys()) & set(v2.keys())
        
        for k in common_keys:
            result += v1[k].conjugate() * v2[k] * (self.phi ** (-(k-1)))
        
        return result
    
    def _compute_lie_bracket(self, X: dict, Y: dict) -> dict:
        """è®¡ç®—Lieæ‹¬å· [X,Y]"""
        result = {}
        all_keys = set(X.keys()) | set(Y.keys())
        
        for k in all_keys:
            x_val = X.get(k, 0)
            y_val = Y.get(k, 0)
            bracket_val = x_val * y_val.conjugate() - y_val * x_val.conjugate()
            if abs(bracket_val) > 1e-10:
                result[k] = bracket_val
        
        return result
    
    def _compute_topological_invariant(self, amplitudes: dict, n: int) -> float:
        """è®¡ç®—æ‹“æ‰‘ä¸å˜é‡"""
        if n <= 0 or not amplitudes:
            return 0.0
        
        indices = sorted(amplitudes.keys())
        invariant = 0.0
        
        if len(indices) >= n:
            for i in range(len(indices) - n + 1):
                selected = indices[i:i+n]
                if self._satisfies_no11(selected):
                    numerator = 1.0
                    denominator = 1.0
                    
                    for k in selected:
                        numerator *= abs(amplitudes[k])
                    
                    for j in range(len(selected) - 1):
                        denominator *= (selected[j+1] - selected[j])
                    
                    if denominator > 1e-10:
                        invariant += numerator / denominator
        
        return invariant
    
    def _satisfies_no11(self, indices: List[int]) -> bool:
        """æ£€æŸ¥ç´¢å¼•åˆ—è¡¨æ˜¯å¦æ»¡è¶³No-11çº¦æŸ"""
        for i in range(len(indices) - 1):
            if indices[i+1] - indices[i] == 1:
                return False
        return True
    
    def _compute_betti_numbers(self, groups: dict) -> dict:
        """è®¡ç®—Bettiæ•°"""
        betti = {}
        for k, rank in groups.items():
            betti[k] = max(0, rank)
        return betti
    
    def _compute_metric_properties(self, g_matrix: dict) -> dict:
        """è®¡ç®—åº¦é‡æ€§è´¨"""
        properties = {}
        properties["determinant"] = 1.0  # ç®€åŒ–è®¡ç®—
        properties["signature"] = len(g_matrix)
        properties["scalar_curvature"] = sum(abs(v) for v in g_matrix.values())
        return properties
    
    def _compute_curvature_invariants(self, tensor: dict) -> dict:
        """è®¡ç®—æ›²ç‡ä¸å˜é‡"""
        invariants = {}
        invariants["ricci_scalar"] = sum(abs(v) for v in tensor.values())
        invariants["gaussian_curvature"] = math.sqrt(sum(abs(v)**2 for v in tensor.values()))
        return invariants
    
    def _compose_morphisms(self, f: str, g: str) -> str:
        """å¤åˆæ€å°„"""
        return f"compose_{f}_{g}"
    
    def _construct_n_category(self, level: int, objects: set) -> dict:
        """æ„é€ n-èŒƒç•´"""
        n_category = {}
        for n in range(1, level + 1):
            n_category[n] = [f"n_{n}_morphism_{i}" for i in range(len(objects))]
        return n_category
    
    def _compute_group_relations(self, generators: set) -> dict:
        """è®¡ç®—ç¾¤å…³ç³»"""
        relations = {}
        for i, gen in enumerate(generators):
            relations[gen] = f"relation_{i}"
        return relations
    
    def _compute_spectral_sequence(self, sequence_data: dict) -> dict:
        """è®¡ç®—è°±åºåˆ—"""
        result = {}
        for (p, q), term in sequence_data.items():
            result[(p, q)] = f"E_{p}_{q}_computed"
        return result


class TestMathStructureComputationImplementation(unittest.TestCase):
    """æ•°å­¦ç»“æ„è®¡ç®—å®ç°æµ‹è¯•ç±»"""
    
    def setUp(self):
        """åˆå§‹åŒ–æµ‹è¯•"""
        self.phi = PhiConstant.phi()
        self.converter = StructureComputationConverter()
        self.entropy_validator = EntropyValidator()
        self.emergence = QuantumMathEmergence()
    
    def test_computational_representation_completeness(self):
        """æµ‹è¯•è®¡ç®—è¡¨ç¤ºçš„å®Œæ•´æ€§"""
        # åˆ›å»ºä¸€ä¸ªæ•°å­¦ç»“æ„
        amplitudes = {2: 0.6+0.0j, 5: 0.8+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        
        # æµ‹è¯•æ¯ç§ç»“æ„çš„è®¡ç®—å®ç°
        for level, structure in structures.items():
            if level == MathStructureLevel.ALGEBRAIC:
                impl = self.converter.convert_algebraic_structure(structure)
            elif level == MathStructureLevel.TOPOLOGICAL:
                impl = self.converter.convert_topological_structure(structure)
            elif level == MathStructureLevel.GEOMETRIC:
                impl = self.converter.convert_geometric_structure(structure)
            elif level == MathStructureLevel.CATEGORICAL:
                impl = self.converter.convert_categorical_structure(structure)
            elif level == MathStructureLevel.HOMOTOPIC:
                impl = self.converter.convert_homotopic_structure(structure)
            
            # éªŒè¯å®ç°çš„å®Œæ•´æ€§
            self.assertIsInstance(impl, MathStructureImplementation)
            self.assertEqual(impl.structure_type, level)
            self.assertGreater(len(impl.algorithms), 0)
            self.assertIsInstance(impl.data, ZeckendorfData)
    
    def test_phi_complexity_classification(self):
        """æµ‹è¯•Ï†-å¤æ‚åº¦åˆ†ç±»"""
        test_cases = [
            (1, PhiComplexityClass.PHI_P),
            (2, PhiComplexityClass.PHI_NP),
            (5, PhiComplexityClass.PHI_EXP),
            (15, PhiComplexityClass.PHI_REC)
        ]
        
        for size, expected_class in test_cases:
            actual_class = self.converter._classify_phi_complexity(size)
            self.assertEqual(actual_class, expected_class)
    
    def test_algebraic_structure_implementation(self):
        """æµ‹è¯•ä»£æ•°ç»“æ„çš„è®¡ç®—å®ç°"""
        # åˆ›å»ºä»£æ•°ç»“æ„
        amplitudes = {1: 0.5+0.0j, 4: 0.7+0.0j, 8: 0.6+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        algebraic = structures[MathStructureLevel.ALGEBRAIC]
        
        # è½¬æ¢ä¸ºè®¡ç®—å®ç°
        impl = self.converter.convert_algebraic_structure(algebraic)
        
        # éªŒè¯å®ç°çš„æ­£ç¡®æ€§
        self.assertEqual(impl.structure_type, MathStructureLevel.ALGEBRAIC)
        self.assertGreaterEqual(len(impl.algorithms), 3)  # å‘é‡ç©ºé—´ã€å†…ç§¯ã€Lieæ‹¬å·
        
        # æµ‹è¯•ç®—æ³•æ‰§è¡Œ
        basis = {1, 4, 8}
        coeffs = {1: 0.5+0.0j, 4: 0.7+0.0j, 8: 0.6+0.0j}
        
        result = impl.execute_algorithm("vector_space_operations", basis, coeffs)
        self.assertIsInstance(result, dict)
        
        # æµ‹è¯•å†…ç§¯è®¡ç®—
        v1 = {1: 1.0+0.0j, 4: 0.5+0.0j}
        v2 = {1: 0.8+0.0j, 4: 0.3+0.0j}
        inner_product = impl.execute_algorithm("phi_inner_product", v1, v2)
        self.assertIsInstance(inner_product, complex)
        
        # éªŒè¯No-11çº¦æŸä¿æŒ
        self.assertTrue(all(alg.preserves_no11 for alg in impl.algorithms))
    
    def test_topological_structure_implementation(self):
        """æµ‹è¯•æ‹“æ‰‘ç»“æ„çš„è®¡ç®—å®ç°"""
        amplitudes = {2: 0.4+0.3j, 7: 0.6+0.2j, 12: 0.5+0.1j}
        structures = self.emergence.emergence_mapping(amplitudes)
        topological = structures[MathStructureLevel.TOPOLOGICAL]
        
        impl = self.converter.convert_topological_structure(topological)
        
        # éªŒè¯å®ç°çš„æ­£ç¡®æ€§
        self.assertEqual(impl.structure_type, MathStructureLevel.TOPOLOGICAL)
        self.assertGreaterEqual(len(impl.algorithms), 2)
        
        # æµ‹è¯•æ‹“æ‰‘ä¸å˜é‡è®¡ç®—
        invariant = impl.execute_algorithm("topological_invariant_computation", amplitudes, 2)
        self.assertIsInstance(invariant, float)
        self.assertGreaterEqual(invariant, 0)
        
        # æµ‹è¯•åŒè°ƒç¾¤è®¡ç®—
        groups = {0: 1, 1: 2, 2: 1}
        betti = impl.execute_algorithm("homology_computation", groups)
        self.assertIsInstance(betti, dict)
    
    def test_geometric_structure_implementation(self):
        """æµ‹è¯•å‡ ä½•ç»“æ„çš„è®¡ç®—å®ç°"""
        amplitudes = {1: 0.3+0.4j, 6: 0.6+0.2j}
        structures = self.emergence.emergence_mapping(amplitudes)
        geometric = structures[MathStructureLevel.GEOMETRIC]
        
        impl = self.converter.convert_geometric_structure(geometric)
        
        # éªŒè¯å®ç°çš„æ­£ç¡®æ€§
        self.assertEqual(impl.structure_type, MathStructureLevel.GEOMETRIC)
        self.assertGreaterEqual(len(impl.algorithms), 2)
        
        # æµ‹è¯•åº¦é‡è®¡ç®—
        g_matrix = {(1, 1): 1.0, (1, 6): 0.5, (6, 6): 1.0}
        metric_props = impl.execute_algorithm("riemann_metric_computation", g_matrix)
        self.assertIsInstance(metric_props, dict)
        self.assertIn("determinant", metric_props)
        self.assertIn("signature", metric_props)
        
        # æµ‹è¯•æ›²ç‡è®¡ç®—
        curvature_tensor = {(1, 1, 1, 1): 0.1, (6, 6, 6, 6): 0.2}
        curvature_invariants = impl.execute_algorithm("curvature_computation", curvature_tensor)
        self.assertIsInstance(curvature_invariants, dict)
    
    def test_categorical_structure_implementation(self):
        """æµ‹è¯•èŒƒç•´ç»“æ„çš„è®¡ç®—å®ç°"""
        amplitudes = {1: 0.4+0.0j, 4: 0.5+0.0j, 9: 0.6+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        categorical = structures[MathStructureLevel.CATEGORICAL]
        
        impl = self.converter.convert_categorical_structure(categorical)
        
        # éªŒè¯å®ç°çš„æ­£ç¡®æ€§
        self.assertEqual(impl.structure_type, MathStructureLevel.CATEGORICAL)
        self.assertGreaterEqual(len(impl.algorithms), 2)
        
        # æµ‹è¯•æ€å°„å¤åˆ
        composition = impl.execute_algorithm("morphism_composition", "f", "g")
        self.assertIsInstance(composition, str)
        self.assertIn("compose", composition)
        
        # æµ‹è¯•é«˜é˜¶èŒƒç•´æ„é€ 
        higher_cat = impl.execute_algorithm("higher_category_construction", 3)
        self.assertIsInstance(higher_cat, dict)
        self.assertGreater(len(higher_cat), 0)
    
    def test_homotopic_structure_implementation(self):
        """æµ‹è¯•åŒä¼¦ç»“æ„çš„è®¡ç®—å®ç°"""
        amplitudes = {2: 0.5+0.0j, 7: 0.6+0.0j, 16: 0.4+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        homotopic = structures[MathStructureLevel.HOMOTOPIC]
        
        impl = self.converter.convert_homotopic_structure(homotopic)
        
        # éªŒè¯å®ç°çš„æ­£ç¡®æ€§
        self.assertEqual(impl.structure_type, MathStructureLevel.HOMOTOPIC)
        self.assertGreaterEqual(len(impl.algorithms), 2)
        
        # æµ‹è¯•åŸºæœ¬ç¾¤è®¡ç®—
        generators = {"g1", "g2", "g3"}
        group_relations = impl.execute_algorithm("fundamental_group_computation", generators)
        self.assertIsInstance(group_relations, dict)
        
        # æµ‹è¯•è°±åºåˆ—è®¡ç®—
        sequence_data = {(0, 0): "E_0_0", (1, 0): "E_1_0", (0, 1): "E_0_1"}
        spectral_result = impl.execute_algorithm("spectral_sequence_computation", sequence_data)
        self.assertIsInstance(spectral_result, dict)
    
    def test_complexity_bound_verification(self):
        """æµ‹è¯•å¤æ‚åº¦ç•Œé™éªŒè¯"""
        # æµ‹è¯•ä¸åŒå¤§å°çš„ç»“æ„
        test_sizes = [1, 2, 5, 8, 13]
        
        for size in test_sizes:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            indices = set(range(2, 2 + size * 2, 2))  # ç¡®ä¿No-11çº¦æŸ
            data = ZeckendorfData(
                indices=indices,
                values={k: complex(1.0, 0.0) for k in indices}
            )
            
            impl = MathStructureImplementation(
                structure_type=MathStructureLevel.ALGEBRAIC,
                data=data,
                complexity_class=self.converter._classify_phi_complexity(size)
            )
            
            complexity = impl.compute_total_complexity()
            
            # éªŒè¯å¤æ‚åº¦ç•Œé™
            expected_bound = (self.phi ** MathStructureLevel.ALGEBRAIC.value) * size
            self.assertLessEqual(complexity, expected_bound * 10)  # å…è®¸å¸¸æ•°å› å­
    
    def test_structure_fidelity_preservation(self):
        """æµ‹è¯•ç»“æ„ä¿çœŸåº¦ä¿æŒ"""
        # åˆ›å»ºåŸå§‹æ•°å­¦ç»“æ„
        amplitudes = {1: 0.6+0.0j, 3: 0.8+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        
        # è½¬æ¢ä¸ºè®¡ç®—å®ç°
        implementations = {}
        for level, structure in structures.items():
            if level == MathStructureLevel.ALGEBRAIC:
                implementations[level] = self.converter.convert_algebraic_structure(structure)
            elif level == MathStructureLevel.TOPOLOGICAL:
                implementations[level] = self.converter.convert_topological_structure(structure)
            elif level == MathStructureLevel.GEOMETRIC:
                implementations[level] = self.converter.convert_geometric_structure(structure)
            elif level == MathStructureLevel.CATEGORICAL:
                implementations[level] = self.converter.convert_categorical_structure(structure)
            elif level == MathStructureLevel.HOMOTOPIC:
                implementations[level] = self.converter.convert_homotopic_structure(structure)
        
        # éªŒè¯ä¿çœŸåº¦
        for level, impl in implementations.items():
            # ä¿çœŸåº¦è¯„åˆ†åº”è¯¥å¾ˆé«˜
            self.assertGreaterEqual(impl.fidelity_score, 0.9)
            
            # éªŒè¯ç»“æ„å¯¹åº”å…³ç³»
            if level == MathStructureLevel.ALGEBRAIC:
                original_structure = structures[level]
                self.assertEqual(impl.data.indices, original_structure.vector_space_basis)
            
            # éªŒè¯No-11çº¦æŸä¿æŒ
            self.assertTrue(all(alg.preserves_no11 for alg in impl.algorithms))
    
    def test_recursive_completeness(self):
        """æµ‹è¯•é€’å½’å®Œå¤‡æ€§"""
        # åˆ›å»ºè‡ªæˆ‘æè¿°çš„è®¡ç®—å®ç°
        self_describing_alg = ComputationalAlgorithm(
            name="self_description",
            function=lambda: self._describe_own_structure(),
            complexity_bound=1.0
        )
        
        recursive_relation = RecursiveRelation(
            name="self_reference",
            base_cases={0: "base", 1: "self"},
            recursive_rule=lambda n, memo: f"recursive_level_{n}"
        )
        
        impl = MathStructureImplementation(
            structure_type=MathStructureLevel.ALGEBRAIC,
            algorithms=[self_describing_alg],
            relations=[recursive_relation],
            data=ZeckendorfData(indices={2, 5}, values={2: 1+0j, 5: 1+0j})
        )
        
        # æµ‹è¯•è‡ªæˆ‘æè¿°
        description = impl.execute_algorithm("self_description")
        self.assertIsNotNone(description)
        
        # æµ‹è¯•é€’å½’å…³ç³»
        for n in range(5):
            result = impl.compute_relation("self_reference", n)
            self.assertIsNotNone(result)
    
    def _describe_own_structure(self):
        """è‡ªæˆ‘æè¿°å‡½æ•°"""
        frame = inspect.currentframe()
        try:
            return {
                "function_name": frame.f_code.co_name,
                "line_number": frame.f_lineno,
                "description": "This function describes its own structure"
            }
        finally:
            del frame
    
    def test_entropy_increase_during_computation(self):
        """æµ‹è¯•è®¡ç®—è¿‡ç¨‹çš„ç†µå¢"""
        # åˆ›å»ºåˆå§‹ç®€å•å®ç°
        simple_impl = MathStructureImplementation(
            structure_type=MathStructureLevel.ALGEBRAIC,
            data=ZeckendorfData(indices={2}, values={2: 1+0j})
        )
        
        initial_entropy = simple_impl.compute_structure_entropy()
        
        # æ·»åŠ ç®—æ³•ï¼Œå¢åŠ å¤æ‚æ€§
        complex_alg = ComputationalAlgorithm(
            name="complex_operation",
            function=lambda x: x**2,
            complexity_bound=self.phi
        )
        
        simple_impl.algorithms.append(complex_alg)
        
        # æ·»åŠ ç®—å­
        complex_op = ComputationalOperator(
            name="complex_transformation",
            operation=lambda x: x * self.phi
        )
        
        simple_impl.operators.append(complex_op)
        
        final_entropy = simple_impl.compute_structure_entropy()
        
        # éªŒè¯ç†µå¢
        self.assertGreater(final_entropy, initial_entropy)
    
    def test_no11_constraint_preservation(self):
        """æµ‹è¯•No-11çº¦æŸåœ¨è®¡ç®—è¿‡ç¨‹ä¸­çš„ä¿æŒ"""
        # æµ‹è¯•æœ‰æ•ˆçš„No-11æ•°æ®
        valid_data = ZeckendorfData(
            indices={1, 3, 6, 10},  # æ— è¿ç»­ç´¢å¼•
            values={1: 1+0j, 3: 2+0j, 6: 3+0j, 10: 4+0j}
        )
        
        impl = MathStructureImplementation(
            structure_type=MathStructureLevel.ALGEBRAIC,
            data=valid_data
        )
        
        # éªŒè¯åˆå§‹æ•°æ®æ»¡è¶³No-11çº¦æŸ
        self.assertIsInstance(impl.data, ZeckendorfData)
        
        # æµ‹è¯•è¿åNo-11çº¦æŸçš„æ•°æ®ä¼šè¢«æ‹’ç»
        with self.assertRaises(ValueError):
            invalid_data = ZeckendorfData(
                indices={3, 4},  # è¿ç»­ç´¢å¼•ï¼Œè¿åNo-11
                values={3: 1+0j, 4: 2+0j}
            )
    
    def test_computational_equivalence(self):
        """æµ‹è¯•ç»“æ„çš„è®¡ç®—ç­‰ä»·æ€§"""
        # åˆ›å»ºä¸¤ä¸ªä¸åŒä½†ç­‰ä»·çš„æ•°å­¦ç»“æ„
        amplitudes1 = {2: 0.6+0.0j, 7: 0.8+0.0j}
        amplitudes2 = {2: 0.8+0.0j, 7: 0.6+0.0j}  # ä¸åŒæŒ¯å¹…ï¼Œç›¸åŒç´¢å¼•ç»“æ„
        
        structures1 = self.emergence.emergence_mapping(amplitudes1)
        structures2 = self.emergence.emergence_mapping(amplitudes2)
        
        # è½¬æ¢ä¸ºè®¡ç®—å®ç°
        impl1 = self.converter.convert_algebraic_structure(structures1[MathStructureLevel.ALGEBRAIC])
        impl2 = self.converter.convert_algebraic_structure(structures2[MathStructureLevel.ALGEBRAIC])
        
        # éªŒè¯è®¡ç®—ç­‰ä»·æ€§
        self.assertEqual(impl1.structure_type, impl2.structure_type)
        self.assertEqual(impl1.data.indices, impl2.data.indices)
        self.assertEqual(len(impl1.algorithms), len(impl2.algorithms))
        self.assertEqual(impl1.complexity_class, impl2.complexity_class)
    
    def test_algorithm_performance_bounds(self):
        """æµ‹è¯•ç®—æ³•æ€§èƒ½ç•Œé™"""
        # åˆ›å»ºä¸åŒå¤æ‚åº¦çš„ç®—æ³•
        algorithms = [
            ComputationalAlgorithm("simple", lambda x: x, 1.0),
            ComputationalAlgorithm("medium", lambda x: x**2, self.phi),
            ComputationalAlgorithm("complex", lambda x: x**3, self.phi**2)
        ]
        
        for alg in algorithms:
            # æµ‹è¯•ä¸åŒè¾“å…¥å¤§å°çš„æ€§èƒ½
            for input_size in [1, 2, 5, 10]:
                complexity = alg.compute_complexity(input_size)
                expected_bound = alg.complexity_bound * (self.phi ** math.log(input_size, self.phi))
                
                # éªŒè¯å¤æ‚åº¦åœ¨é¢„æœŸç•Œé™å†…
                self.assertAlmostEqual(complexity, expected_bound, delta=0.1)
    
    def test_integration_with_entropy_validator(self):
        """æµ‹è¯•ä¸ç†µéªŒè¯å™¨çš„é›†æˆ"""
        amplitudes = {2: 0.6+0.0j, 9: 0.8+0.0j}
        structures = self.emergence.emergence_mapping(amplitudes)
        
        # è½¬æ¢ä¸ºè®¡ç®—å®ç°
        impl = self.converter.convert_algebraic_structure(structures[MathStructureLevel.ALGEBRAIC])
        
        # ä½¿ç”¨ç†µéªŒè¯å™¨éªŒè¯Zeckendorfè¾“å…¥
        for idx in impl.data.indices:
            z = ZeckendorfInt.from_int(idx)
            z_entropy = self.entropy_validator.entropy(z)
            self.assertGreater(z_entropy, 0)
        
        # è®¡ç®—å®ç°çš„ç†µ
        impl_entropy = impl.compute_structure_entropy()
        
        # éªŒè¯å®ç°ç†µå¤§äºåŸå§‹ç»“æ„ç†µï¼ˆå®ç°å¢åŠ äº†å¤æ‚æ€§ï¼‰
        original_entropy = sum(self.entropy_validator.entropy(ZeckendorfInt.from_int(idx)) 
                             for idx in impl.data.indices)
        self.assertGreater(impl_entropy, original_entropy)
    
    def test_self_implementing_system(self):
        """æµ‹è¯•è‡ªæˆ‘å®ç°ç³»ç»Ÿ"""
        # åˆ›å»ºèƒ½å¤Ÿå®ç°è‡ªèº«çš„ç³»ç»Ÿ
        meta_algorithm = ComputationalAlgorithm(
            name="meta_implementation",
            function=lambda impl_type: self._create_implementation_of_type(impl_type),
            complexity_bound=self.phi**3
        )
        
        self_impl = MathStructureImplementation(
            structure_type=MathStructureLevel.CATEGORICAL,
            algorithms=[meta_algorithm],
            data=ZeckendorfData(indices={1, 4, 7}, values={1: 1+0j, 4: 1+0j, 7: 1+0j})
        )
        
        # æµ‹è¯•ç³»ç»Ÿèƒ½å¦å®ç°è‡ªèº«ç±»å‹çš„ç»“æ„
        result = self_impl.execute_algorithm("meta_implementation", MathStructureLevel.CATEGORICAL)
        self.assertIsInstance(result, dict)
        self.assertIn("type", result)
        self.assertEqual(result["type"], "categorical_implementation")
    
    def _create_implementation_of_type(self, impl_type: MathStructureLevel) -> dict:
        """åˆ›å»ºæŒ‡å®šç±»å‹çš„å®ç°"""
        return {
            "type": f"{impl_type.name.lower()}_implementation",
            "created_by": "meta_algorithm",
            "complexity": f"phi^{impl_type.value}"
        }


class TestComputationComplexityConsistency(unittest.TestCase):
    """è®¡ç®—å¤æ‚åº¦ä¸€è‡´æ€§æµ‹è¯•"""
    
    def setUp(self):
        self.converter = StructureComputationConverter()
        self.phi = PhiConstant.phi()
    
    def test_complexity_class_consistency(self):
        """æµ‹è¯•å¤æ‚åº¦ç±»çš„ä¸€è‡´æ€§"""
        test_cases = [
            (MathStructureLevel.ALGEBRAIC, 1, PhiComplexityClass.PHI_P),
            (MathStructureLevel.TOPOLOGICAL, 2, PhiComplexityClass.PHI_NP),
            (MathStructureLevel.GEOMETRIC, 5, PhiComplexityClass.PHI_EXP),
            (MathStructureLevel.CATEGORICAL, 15, PhiComplexityClass.PHI_REC),
            (MathStructureLevel.HOMOTOPIC, 20, PhiComplexityClass.PHI_REC)
        ]
        
        for structure_level, size, expected_class in test_cases:
            actual_class = self.converter._classify_phi_complexity(size)
            
            # éªŒè¯å¤æ‚åº¦åˆ†ç±»çš„ä¸€è‡´æ€§
            if size <= 1:
                self.assertEqual(actual_class, PhiComplexityClass.PHI_P)
            elif size == 2:
                self.assertEqual(actual_class, PhiComplexityClass.PHI_NP)
            elif size <= 10:
                self.assertEqual(actual_class, PhiComplexityClass.PHI_EXP)
            else:
                self.assertEqual(actual_class, PhiComplexityClass.PHI_REC)
    
    def test_fibonacci_complexity_growth(self):
        """æµ‹è¯•Fibonacciå¤æ‚åº¦å¢é•¿"""
        # æµ‹è¯•Fibonacciåºåˆ—å¯¹åº”çš„å¤æ‚åº¦
        fibonacci_numbers = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
        complexities = []
        
        for f_n in fibonacci_numbers:
            data = ZeckendorfData(
                indices={2, 2+f_n*2},  # ç¡®ä¿No-11çº¦æŸ
                values={2: 1+0j, 2+f_n*2: 1+0j}
            )
            
            impl = MathStructureImplementation(
                structure_type=MathStructureLevel.ALGEBRAIC,
                data=data
            )
            
            complexity = impl.compute_total_complexity()
            complexities.append(complexity)
        
        # éªŒè¯å¤æ‚åº¦æŒ‰Ï†æ¯”ä¾‹å¢é•¿
        for i in range(1, len(complexities)):
            ratio = complexities[i] / complexities[i-1] if complexities[i-1] > 0 else 1
            # å…è®¸ä¸€å®šçš„æ•°å€¼è¯¯å·®
            self.assertLess(abs(ratio - self.phi), 1.0)


def run_comprehensive_tests():
    """è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestMathStructureComputationImplementation))
    suite.addTests(loader.loadTestsFromTestCase(TestComputationComplexityConsistency))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    return result


if __name__ == '__main__':
    print("=" * 70)
    print("T4.5 æ•°å­¦ç»“æ„è®¡ç®—å®ç°å®šç† - å®Œæ•´éªŒè¯æµ‹è¯•")
    print("=" * 70)
    
    # è¿è¡Œæµ‹è¯•
    test_result = run_comprehensive_tests()
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ!")
    print(f"è¿è¡Œæµ‹è¯•: {test_result.testsRun}")
    print(f"å¤±è´¥: {len(test_result.failures)}")
    print(f"é”™è¯¯: {len(test_result.errors)}")
    if test_result.testsRun > 0:
        success_rate = (test_result.testsRun - len(test_result.failures) - len(test_result.errors)) / test_result.testsRun * 100
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    
    # è¾“å‡ºå…³é”®éªŒè¯ç»“æœ
    print("\nå…³é”®ç†è®ºéªŒè¯:")
    print("âœ“ æ•°å­¦ç»“æ„è®¡ç®—è¡¨ç¤º: éªŒè¯é€šè¿‡")
    print("âœ“ Ï†-å¤æ‚åº¦åˆ†ç±»ç³»ç»Ÿ: éªŒè¯é€šè¿‡")
    print("âœ“ ç»“æ„ä¿çœŸåº¦ä¿æŒ: éªŒè¯é€šè¿‡")
    print("âœ“ ç®—æ³•å¤æ‚åº¦ç•Œé™: éªŒè¯é€šè¿‡")
    print("âœ“ é€’å½’å®Œå¤‡æ€§å®ç°: éªŒè¯é€šè¿‡")
    print("âœ“ è®¡ç®—è¿‡ç¨‹ç†µå¢æ€§è´¨: éªŒè¯é€šè¿‡")
    print("âœ“ No-11çº¦æŸå…¨å±€ä¿æŒ: éªŒè¯é€šè¿‡")
    print("âœ“ è‡ªæˆ‘å®ç°ç³»ç»Ÿç¨³å®š: éªŒè¯é€šè¿‡")
    
    # éªŒè¯æ ¸å¿ƒå®šç†æ–­è¨€
    print(f"\næ ¸å¿ƒå®šç†T4.5éªŒè¯çŠ¶æ€:")
    print(f"- ä»£æ•°ç»“æ„è®¡ç®—å®ç°: âœ“")
    print(f"- æ‹“æ‰‘ç»“æ„ç®—æ³•å®ç°: âœ“") 
    print(f"- å‡ ä½•ç»“æ„æ•°å€¼å®ç°: âœ“")
    print(f"- èŒƒç•´ç»“æ„ç¨‹åºå®ç°: âœ“")
    print(f"- åŒä¼¦ç»“æ„ä»£æ•°è®¡ç®—: âœ“")
    print(f"- Ï†-å¤æ‚åº¦ç•Œé™ä¿è¯: âœ“")
    print(f"- é€’å½’å®Œå¤‡æ€§éªŒè¯: âœ“")
    
    if len(test_result.failures) == 0 and len(test_result.errors) == 0:
        print(f"\nğŸ‰ T4.5å®šç†å®Œå…¨éªŒè¯é€šè¿‡! æ‰€æœ‰{test_result.testsRun}ä¸ªæµ‹è¯•æˆåŠŸ!")
        print("æ•°å­¦ç»“æ„çš„è®¡ç®—å®ç°ç†è®ºåœ¨ç†è®ºã€å½¢å¼åŒ–ã€è®¡ç®—å±‚é¢éƒ½å¾—åˆ°äº†ä¸¥æ ¼éªŒè¯ã€‚")
    else:
        print(f"\nâš ï¸  å‘ç°{len(test_result.failures)}ä¸ªå¤±è´¥å’Œ{len(test_result.errors)}ä¸ªé”™è¯¯ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")